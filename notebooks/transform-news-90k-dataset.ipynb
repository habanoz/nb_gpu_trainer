{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/melek/workspace/vscode/nb_gpu_trainer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/melek/workspace/vscode/nb_gpu_trainer\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers in ./.conda/lib/python3.10/site-packages (from nb_gpu_trainer==1.0) (4.42.4)\n",
      "Requirement already satisfied: datasets in ./.conda/lib/python3.10/site-packages (from nb_gpu_trainer==1.0) (2.20.0)\n",
      "Requirement already satisfied: huggingface-hub in ./.conda/lib/python3.10/site-packages (from nb_gpu_trainer==1.0) (0.24.0)\n",
      "Requirement already satisfied: sentencepiece in ./.conda/lib/python3.10/site-packages (from nb_gpu_trainer==1.0) (0.2.0)\n",
      "Collecting wandb (from nb_gpu_trainer==1.0)\n",
      "  Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in ./.conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->nb_gpu_trainer==1.0) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (3.9.5)\n",
      "Requirement already satisfied: packaging in /home/melek/.local/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/lib/python3.10/site-packages (from datasets->nb_gpu_trainer==1.0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/melek/.local/lib/python3.10/site-packages (from huggingface-hub->nb_gpu_trainer==1.0) (4.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/lib/python3.10/site-packages (from transformers->nb_gpu_trainer==1.0) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.conda/lib/python3.10/site-packages (from transformers->nb_gpu_trainer==1.0) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.conda/lib/python3.10/site-packages (from transformers->nb_gpu_trainer==1.0) (0.19.1)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /home/melek/.local/lib/python3.10/site-packages (from wandb->nb_gpu_trainer==1.0) (4.2.0)\n",
      "Collecting protobuf!=4.21.0,<6,>=3.19.0 (from wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./.conda/lib/python3.10/site-packages (from wandb->nb_gpu_trainer==1.0) (6.0.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached sentry_sdk-2.10.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting setproctitle (from wandb->nb_gpu_trainer==1.0)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.10/site-packages (from wandb->nb_gpu_trainer==1.0) (71.0.1)\n",
      "Requirement already satisfied: six>=1.4.0 in ./.conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->nb_gpu_trainer==1.0) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/melek/.local/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.conda/lib/python3.10/site-packages (from aiohttp->datasets->nb_gpu_trainer==1.0) (4.0.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/melek/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets->nb_gpu_trainer==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->nb_gpu_trainer==1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->nb_gpu_trainer==1.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->nb_gpu_trainer==1.0) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/melek/.local/lib/python3.10/site-packages (from pandas->datasets->nb_gpu_trainer==1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas->datasets->nb_gpu_trainer==1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.10/site-packages (from pandas->datasets->nb_gpu_trainer==1.0) (2024.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nb_gpu_trainer==1.0)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "Using cached sentry_sdk-2.10.0-py2.py3-none-any.whl (302 kB)\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: nb_gpu_trainer\n",
      "  Building editable for nb_gpu_trainer (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nb_gpu_trainer: filename=nb_gpu_trainer-1.0-0.editable-py3-none-any.whl size=2141 sha256=c5e06cec8c2223615ac67f603c4b6cd5a37bcdebf027c2274e1cb570eb9e1ed8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-putzrn9p/wheels/f0/71/63/52e6a2e2ba1f40586e31bdb7b0b78706e7d3d90f16ac37a95e\n",
      "Successfully built nb_gpu_trainer\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, click, gitdb, gitpython, wandb, nb_gpu_trainer\n",
      "  Attempting uninstall: nb_gpu_trainer\n",
      "    Found existing installation: nb_gpu_trainer 1.0\n",
      "    Uninstalling nb_gpu_trainer-1.0:\n",
      "      Successfully uninstalled nb_gpu_trainer-1.0\n",
      "Successfully installed click-8.1.7 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 nb_gpu_trainer-1.0 protobuf-5.27.2 sentry-sdk-2.10.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerConfig\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tokenizer'"
     ]
    }
   ],
   "source": [
    "from tokenizer.train import Trainer\n",
    "from huggingface_hub import login\n",
    "from trainer import TrainerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a4757d93e74ada88e0752cbfcb21c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file)->TrainerConfig:\n",
    "    import yaml\n",
    "\n",
    "    with open(config_file) as f:\n",
    "        try:\n",
    "            doc = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "            exit(1)\n",
    "    \n",
    "    return TrainerConfig(**doc)\n",
    "\n",
    "trainer_cfg = load_config(\"config/news_trainer.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('habanoz/haber-90k-gpt-v1.0', 'haber-90k-gpt', 'habanoz/haber-90k-gpt-text')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_cfg.repo_id, trainer_cfg.out_dir, trainer_cfg.ds_repo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a694c11ff3cd4161bacbedbada68cd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb56bbfd654a40948fb58a42ac3cdd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/154M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a6d5b04ff4e8d8dc614ffd27af168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cef2fe5168c455197b5aa81426dfc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/81708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6355c2ac28644c28a2bc5cae1721443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9079 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"habanoz/news-tr-90k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ds['train'].train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__'],\n",
       "        num_rows: 81708\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__'],\n",
       "        num_rows: 9079\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_doc(x):\n",
    "    return f\"\"\"# {x['Title']}\n",
    "\n",
    "## Özet\n",
    "\n",
    "{x['Summary']}\n",
    "\n",
    "## İçerik\n",
    "\n",
    "{x['Text']}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a79240d698f47509adeed615adb1303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e2b10944ab4bd78429a6ef743556d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9079 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dss = dss.map(lambda x: {'doc':to_doc(x)}, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__', 'doc'],\n",
       "        num_rows: 81708\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__', 'doc'],\n",
       "        num_rows: 9079\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = DatasetDict({\n",
    "    \"train\":dss['train'],\n",
    "    \"validation\":dss['test'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__', 'doc'],\n",
       "        num_rows: 81708\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__', 'doc'],\n",
       "        num_rows: 9079\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = dss.remove_columns(['Id', 'Tag', 'Labels', 'Title', 'Summary', 'Text', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = dss.rename_column('doc','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beace8035d9f4119ba54e82e08b1ea48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09504ad0e80f40558b3ba010f4a7b0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/82 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf5d24e66b4e54bf50aaf13354ded1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cea6c2681446f2846c7b9216842b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/habanoz/haber-90k-gpt-text/commit/c02f66b5bdb10cac0c062492f39f6a6adc8ec3a6', commit_message='Upload dataset', commit_description='', oid='c02f66b5bdb10cac0c062492f39f6a6adc8ec3a6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.push_to_hub(\"habanoz/haber-90k-gpt-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
