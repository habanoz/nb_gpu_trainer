{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/melek/workspace/vscode/nb_gpu_trainer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtr.model.gpt2 import GPT\n",
    "from huggingface_hub import HfApi, login\n",
    "from transformers.utils import cached_file\n",
    "from nbtr.trainer import TrainerConfig\n",
    "from nbtr.tokenizer.tokenizer import Tokenizer\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4139b5b4c3b44ef49a8f1aff707ea773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cfg_file = \"config/news_trainer.yml\"\n",
    "model_cfg_file = \"config/news_model.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file)->TrainerConfig:\n",
    "    import yaml\n",
    "\n",
    "    with open(config_file) as f:\n",
    "        try:\n",
    "            doc = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "            exit(1)\n",
    "\n",
    "    return TrainerConfig(**doc)\n",
    "\n",
    "trainer_cfg = load_config(trainer_cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainerConfig(seq_length=1024, gradient_accumulation_steps=1, batch_size=32, ds_repo_id='habanoz/haber-90k-gpt-text', data_dir='haber-90k-data', warmup_iters=100, learning_rate=0.001, lr_decay_iters=6000, max_iters=6000, min_lr=0.0001, weight_decay=0.1, beta1=0.9, beta2=0.99, compile=False, decay_lr=True, seed=145, log_interval=10, eval_interval=250, eval_iters=200, out_dir='haber-90k-gpt', wandb_log=True, wandb_project='NB-Haber-GPT-Training', wandb_run_name='haber-90k-gpt-v1.1', wandb_run_id='1721342907', grad_norm_clip=1.0, repo_id='habanoz/haber-90k-gpt-v1.1', dtype='float16')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 13.77M\n"
     ]
    }
   ],
   "source": [
    "model = GPT.from_config(model_cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_file = cached_file(trainer_cfg.repo_id, 'pytorch_model.bin', _raise_exceptions_for_missing_entries=True)\n",
    "model_state = torch.load(model_state_file, map_location=torch.device('cpu') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer.wte.weight',\n",
       "              tensor([[-0.0752,  0.0476,  0.0475,  ...,  0.0478, -0.0786, -0.0520],\n",
       "                      [-0.0718,  0.0046,  0.0576,  ...,  0.0493,  0.1173, -0.0925],\n",
       "                      [-0.0501, -0.0143,  0.0728,  ..., -0.0714,  0.0358, -0.0427],\n",
       "                      ...,\n",
       "                      [-0.1071,  0.0943,  0.0424,  ...,  0.0363, -0.0365, -0.1093],\n",
       "                      [-0.0192,  0.1526, -0.0411,  ..., -0.0109,  0.0851, -0.0512],\n",
       "                      [-0.0548, -0.0823, -0.0603,  ...,  0.0006, -0.0392, -0.0501]])),\n",
       "             ('transformer.wpe.weight',\n",
       "              tensor([[-0.0372, -0.0017,  0.0021,  ...,  0.0157,  0.1006, -0.0074],\n",
       "                      [ 0.0082, -0.0188, -0.0340,  ...,  0.0199, -0.0530,  0.0315],\n",
       "                      [ 0.0218, -0.0203, -0.0347,  ..., -0.0068, -0.0357,  0.0164],\n",
       "                      ...,\n",
       "                      [-0.0253, -0.0465,  0.0201,  ...,  0.0205, -0.0246, -0.0014],\n",
       "                      [-0.0040, -0.0324,  0.0147,  ...,  0.0271, -0.0292,  0.0009],\n",
       "                      [-0.0323, -0.0461,  0.0109,  ...,  0.0122, -0.0251, -0.0036]])),\n",
       "             ('transformer.h.0.ln_1.weight',\n",
       "              tensor([0.4718, 0.5934, 0.6412, 0.6104, 0.5539, 0.6368, 0.6137, 0.4600, 0.4562,\n",
       "                      0.6914, 0.5147, 0.5455, 0.5231, 0.5481, 0.6057, 0.5113, 0.5756, 0.5569,\n",
       "                      0.5710, 0.7792, 0.6026, 0.5299, 0.4563, 0.4597, 0.5069, 0.6591, 0.5158,\n",
       "                      0.6331, 0.5629, 0.5168, 0.5514, 0.5167, 0.6084, 0.6235, 0.5413, 0.5087,\n",
       "                      0.5504, 0.5460, 0.5380, 0.6296, 0.5517, 0.5545, 0.5910, 0.6426, 0.5398,\n",
       "                      0.5951, 0.5377, 0.6647, 0.5034, 0.6040, 0.6017, 0.4960, 0.5480, 0.4778,\n",
       "                      0.6082, 0.4788, 0.5574, 0.6191, 0.5115, 0.4859, 0.5602, 0.4836, 0.5973,\n",
       "                      0.4483, 0.5962, 0.5276, 0.5117, 0.6428, 0.4943, 0.5740, 0.5934, 0.5153,\n",
       "                      0.4945, 0.5214, 0.5058, 0.5980, 0.6675, 0.6773, 0.5433, 0.5827, 0.4904,\n",
       "                      0.5731, 0.5176, 0.5602, 0.5557, 0.5845, 0.6467, 0.6689, 0.5443, 0.5529,\n",
       "                      0.5949, 0.5153, 0.5489, 0.4746, 0.4884, 0.5752, 0.5550, 0.5725, 0.5589,\n",
       "                      0.5575, 0.5891, 0.5393, 0.5364, 0.5757, 0.5588, 0.5617, 0.5435, 0.5899,\n",
       "                      0.4731, 0.5351, 0.4867, 0.5100, 0.6399, 0.5188, 0.5958, 0.5282, 0.5704,\n",
       "                      0.5127, 0.6534, 0.5877, 0.4362, 0.7013, 0.5513, 0.5782, 0.6331, 0.6412,\n",
       "                      0.7388, 0.4824, 0.6269, 0.5583, 0.4721, 0.6929, 0.7327, 0.5743, 0.5912,\n",
       "                      0.4726, 0.6130, 0.5696, 0.5593, 0.5492, 0.5657, 0.5230, 0.4149, 0.6771,\n",
       "                      0.6676, 0.5458, 0.5775, 0.6094, 0.5378, 0.5733, 0.6008, 0.7496, 0.6204,\n",
       "                      0.5949, 0.6874, 0.5588, 0.4433, 0.5533, 0.5117, 0.7193, 0.4437, 0.5233,\n",
       "                      0.5428, 0.5254, 0.6449, 0.7035, 0.6020, 0.6183, 0.5823, 0.5148, 0.5192,\n",
       "                      0.6075, 0.4704, 0.5848, 0.5727, 0.5526, 0.6200, 0.5361, 0.5610, 0.4996,\n",
       "                      0.5640, 0.5641, 0.5859, 0.5455, 0.6007, 0.5123, 0.5997, 0.7815, 0.6203,\n",
       "                      0.5485, 0.4906, 0.5346, 0.6706, 0.4452, 0.6175, 0.5095, 0.5663, 0.5249,\n",
       "                      0.4855, 0.6940, 0.5261, 0.5898, 0.5741, 0.5735, 0.5974, 0.5708, 0.6717,\n",
       "                      0.6028, 0.4879, 0.5462, 0.5181, 0.5723, 0.4569, 0.5275, 0.5734, 0.6061,\n",
       "                      0.5961, 0.5321, 0.5788, 0.5723, 0.6864, 0.5338, 0.5755, 0.5392, 0.5659,\n",
       "                      0.2255, 0.6558, 0.7973, 0.5492, 0.3619, 0.5313, 0.4948, 0.6220, 0.5870,\n",
       "                      0.5533, 0.5672, 0.6415, 0.4981, 0.5183, 0.4520, 0.5669, 0.5176, 0.5933,\n",
       "                      0.6007, 0.4296, 0.6528, 0.6160, 0.5052, 0.4810, 0.5914, 0.5980, 0.5467,\n",
       "                      0.5837, 0.5774, 0.5338, 0.5874, 0.5576, 0.4801, 0.4784, 0.6099, 0.5493,\n",
       "                      0.5323, 0.4500, 0.4791, 0.4590, 0.6110, 0.5738, 0.5595, 0.6626, 0.5082,\n",
       "                      0.6737, 0.6514, 0.6983, 0.4766, 0.5439, 0.5259, 0.5564, 0.5037, 0.6022,\n",
       "                      0.7110, 0.5370, 0.6026, 0.5664, 0.6246, 0.6375, 0.6290, 0.6705, 0.5460,\n",
       "                      0.6180, 0.5571, 0.5543, 0.5344, 0.5343, 0.6600, 0.6498, 0.6410, 0.6619,\n",
       "                      0.4584, 0.4715, 0.5235, 0.5442, 0.6381, 0.6383, 0.5509, 0.3297, 0.4751,\n",
       "                      0.5271, 0.5453, 0.7407, 0.5436, 0.5338, 0.5394, 0.7437, 0.5857, 0.5112,\n",
       "                      0.5540, 0.5562, 0.5875, 0.5570, 0.5124, 0.4963, 0.4993, 0.5856, 0.5612,\n",
       "                      0.6116, 0.7848, 0.5162, 0.5245, 0.4803, 0.6426, 0.6186, 0.5590, 0.4426,\n",
       "                      0.6705, 0.5166, 0.4584, 0.5746, 0.6139, 0.4175, 0.5395, 0.5893, 0.4896,\n",
       "                      0.5207, 0.5540, 0.6003, 0.5130, 0.5449, 0.6317, 0.5618, 0.5335, 0.5273,\n",
       "                      0.6954, 0.6753, 0.5363, 0.5993, 0.5021, 0.4910, 0.4985, 0.4820, 0.4893,\n",
       "                      0.5742, 0.6305, 0.5835, 0.6378, 0.5126, 0.5471, 0.5987, 0.5383, 0.5771,\n",
       "                      0.5666, 0.5669, 0.5880, 0.5259, 0.4443, 0.5825, 0.5431, 0.6232, 0.4895,\n",
       "                      0.6762, 0.5796, 0.6681, 0.5322, 0.4435, 0.5947])),\n",
       "             ('transformer.h.0.attn.c_attn.weight',\n",
       "              tensor([[-0.0968,  0.0448,  0.0072,  ...,  0.0965,  0.0426, -0.0302],\n",
       "                      [ 0.0218, -0.0925, -0.0714,  ...,  0.0170,  0.0225,  0.0347],\n",
       "                      [-0.0007,  0.0666, -0.0227,  ...,  0.0206, -0.0460,  0.0672],\n",
       "                      ...,\n",
       "                      [ 0.0129,  0.0025, -0.0036,  ..., -0.0095,  0.0126, -0.0032],\n",
       "                      [ 0.0055, -0.0030, -0.0124,  ...,  0.0046, -0.0143,  0.0286],\n",
       "                      [-0.0081,  0.0069,  0.0125,  ..., -0.0115, -0.0007, -0.0143]])),\n",
       "             ('transformer.h.0.attn.c_proj.weight',\n",
       "              tensor([[ 0.0385,  0.0279, -0.0024,  ...,  0.0036, -0.0071,  0.0168],\n",
       "                      [ 0.0151,  0.0086, -0.0267,  ...,  0.0073, -0.0051,  0.0126],\n",
       "                      [ 0.0045, -0.0211, -0.0261,  ...,  0.0066, -0.0023, -0.0160],\n",
       "                      ...,\n",
       "                      [-0.0212, -0.0179,  0.0223,  ..., -0.0145,  0.0121,  0.0244],\n",
       "                      [ 0.0490, -0.0066, -0.0002,  ..., -0.0030,  0.0051,  0.0044],\n",
       "                      [ 0.0062, -0.0021,  0.0102,  ..., -0.0096,  0.0133, -0.0058]])),\n",
       "             ('transformer.h.0.ln_2.weight',\n",
       "              tensor([0.9087, 0.8988, 0.9766, 0.9195, 0.9363, 0.9564, 0.9016, 0.9092, 0.9337,\n",
       "                      0.9214, 0.9206, 0.9524, 0.9023, 0.9378, 0.8551, 0.8774, 0.9324, 0.8963,\n",
       "                      0.8972, 0.9864, 0.9472, 0.9671, 0.9412, 0.9076, 0.8934, 0.9629, 0.9196,\n",
       "                      0.9339, 0.9374, 0.9620, 0.9576, 0.9143, 1.0095, 0.9848, 0.9450, 0.8385,\n",
       "                      0.9196, 0.9182, 0.9507, 0.9215, 0.9321, 0.9411, 0.9743, 1.0165, 0.9350,\n",
       "                      0.9088, 0.9087, 0.9474, 0.9603, 0.9719, 0.9292, 0.9556, 0.9014, 0.9327,\n",
       "                      1.0274, 0.9092, 0.9382, 0.9439, 0.9288, 0.9292, 0.9837, 0.8891, 0.9712,\n",
       "                      0.9304, 0.9431, 0.9043, 0.9306, 0.9565, 0.9364, 0.9452, 0.8696, 0.8832,\n",
       "                      0.9178, 0.9796, 0.9270, 0.9372, 1.0250, 1.0013, 0.8564, 0.9004, 0.8669,\n",
       "                      0.8046, 0.9559, 0.9372, 0.9159, 0.9319, 0.9506, 1.0237, 0.9770, 1.0059,\n",
       "                      0.9255, 0.9538, 0.8933, 0.8511, 0.9437, 0.9733, 0.9340, 0.8698, 0.9497,\n",
       "                      0.9310, 0.9139, 0.9506, 0.9449, 0.9178, 0.9216, 0.9192, 0.9507, 0.9847,\n",
       "                      0.8910, 0.9228, 0.9396, 0.9160, 0.9726, 0.8598, 0.9301, 0.9564, 0.9558,\n",
       "                      0.9029, 0.9509, 0.9304, 0.9167, 0.9765, 0.9878, 0.8783, 0.8905, 0.8902,\n",
       "                      1.1056, 0.8993, 0.9116, 0.8776, 0.8606, 0.9435, 0.9751, 0.9636, 0.9374,\n",
       "                      0.8321, 0.9688, 0.8918, 0.9674, 0.9448, 0.8881, 0.9398, 0.7658, 0.9890,\n",
       "                      1.0604, 0.8812, 0.9671, 0.9608, 0.8974, 0.9162, 0.9475, 0.9855, 0.9233,\n",
       "                      0.9391, 0.9847, 0.9643, 0.9220, 0.9403, 0.8610, 1.0458, 0.9115, 0.8998,\n",
       "                      0.9152, 0.8853, 1.0201, 1.0473, 0.9588, 0.9696, 0.9021, 0.9263, 0.9580,\n",
       "                      0.9542, 0.9330, 0.9587, 0.8464, 0.9801, 0.9106, 0.9324, 0.9430, 0.8941,\n",
       "                      0.9201, 0.9739, 0.9598, 0.9280, 0.9184, 0.9153, 1.0091, 1.0094, 0.9075,\n",
       "                      0.8984, 0.9032, 0.9501, 0.9654, 0.9223, 0.9817, 0.9085, 0.9190, 0.9471,\n",
       "                      0.9128, 0.9800, 0.8981, 1.0568, 0.8972, 1.0013, 0.9723, 0.9077, 1.0158,\n",
       "                      0.9582, 0.8691, 0.9338, 0.9937, 0.9414, 0.9204, 0.9562, 0.9248, 0.9238,\n",
       "                      0.9402, 0.9010, 0.9389, 0.9020, 0.9337, 0.9513, 0.9587, 0.9461, 0.9564,\n",
       "                      0.7110, 0.9215, 0.9670, 0.9414, 0.8283, 0.9538, 0.9346, 0.9554, 0.8896,\n",
       "                      0.9199, 0.9571, 0.9439, 0.8601, 0.9349, 0.8540, 0.8766, 0.9066, 0.9104,\n",
       "                      0.9378, 0.9027, 0.9832, 0.9054, 0.9869, 0.8914, 0.9209, 0.9584, 0.9210,\n",
       "                      0.9362, 0.9699, 0.9200, 0.9343, 0.9239, 0.9298, 0.8722, 0.9782, 0.9116,\n",
       "                      0.9320, 0.9201, 0.8960, 0.9890, 1.0058, 0.8855, 0.9116, 0.9552, 0.8566,\n",
       "                      0.9424, 0.9791, 1.0184, 0.9287, 0.8888, 0.9092, 0.9670, 0.8936, 0.9497,\n",
       "                      1.0923, 0.9542, 0.9874, 0.8834, 0.9351, 0.8980, 1.0103, 0.9959, 0.9460,\n",
       "                      0.8618, 0.9763, 0.9631, 0.9252, 0.9480, 0.9579, 0.9175, 0.9784, 0.9723,\n",
       "                      0.7436, 0.9351, 0.9385, 0.9122, 0.9094, 1.0395, 0.9376, 0.8521, 0.9778,\n",
       "                      0.9723, 0.9389, 0.9558, 0.9770, 0.8949, 0.9471, 0.9904, 0.9562, 0.9544,\n",
       "                      0.8908, 0.9532, 0.9522, 0.9422, 0.9275, 0.9074, 0.9745, 0.9370, 0.9351,\n",
       "                      0.9776, 0.9628, 0.9047, 0.9024, 0.9454, 1.0645, 0.8948, 0.9623, 0.9541,\n",
       "                      1.0080, 0.9163, 0.7857, 0.9095, 0.9681, 0.8270, 0.9048, 0.9810, 0.9425,\n",
       "                      0.9551, 0.9237, 0.9762, 0.9336, 0.9177, 0.9043, 0.9486, 0.9360, 0.9259,\n",
       "                      1.0067, 0.9443, 0.8810, 0.9619, 0.9068, 0.8746, 0.9187, 0.8866, 0.9182,\n",
       "                      0.9761, 0.9948, 0.9132, 0.9483, 0.9055, 0.9242, 0.9590, 0.9089, 0.8796,\n",
       "                      0.9398, 0.9061, 0.9349, 0.9285, 0.8422, 0.9593, 0.9305, 0.9898, 0.9096,\n",
       "                      0.9326, 0.9264, 0.9570, 0.9100, 0.8804, 1.0153])),\n",
       "             ('transformer.h.0.mlp.c_fc.weight',\n",
       "              tensor([[-0.0187,  0.0539,  0.0404,  ...,  0.0498,  0.0010,  0.0124],\n",
       "                      [ 0.0479,  0.0331,  0.0012,  ..., -0.0282, -0.0218, -0.0102],\n",
       "                      [ 0.0056,  0.0373, -0.0167,  ..., -0.0018,  0.0084,  0.0334],\n",
       "                      ...,\n",
       "                      [ 0.0437, -0.0321, -0.0426,  ...,  0.0551, -0.0136, -0.0075],\n",
       "                      [-0.0281,  0.0241,  0.0466,  ..., -0.0116,  0.0906,  0.0355],\n",
       "                      [ 0.0484, -0.0099, -0.0693,  ..., -0.0048, -0.0077,  0.0219]])),\n",
       "             ('transformer.h.0.mlp.c_proj.weight',\n",
       "              tensor([[-0.0581,  0.0090, -0.0004,  ..., -0.0051,  0.0185,  0.0382],\n",
       "                      [ 0.0215, -0.0115, -0.0407,  ..., -0.0039, -0.0234, -0.0101],\n",
       "                      [ 0.0012,  0.0099, -0.0298,  ..., -0.0815,  0.0327, -0.0334],\n",
       "                      ...,\n",
       "                      [ 0.0335, -0.0089,  0.0257,  ..., -0.0493, -0.0095, -0.0007],\n",
       "                      [ 0.0477,  0.0075,  0.0374,  ..., -0.0176, -0.0057, -0.0034],\n",
       "                      [ 0.0117,  0.0900, -0.0295,  ...,  0.0293,  0.0531,  0.0243]])),\n",
       "             ('transformer.h.1.ln_1.weight',\n",
       "              tensor([0.7238, 0.7356, 0.7733, 0.8078, 0.7752, 0.8777, 0.7672, 0.7191, 0.7530,\n",
       "                      0.9361, 0.8972, 0.8235, 0.8340, 0.8141, 0.7132, 0.6983, 0.8786, 0.8235,\n",
       "                      0.7878, 0.9777, 0.7258, 0.7870, 0.7781, 0.7926, 0.8028, 0.9418, 0.8740,\n",
       "                      0.6688, 0.7873, 0.8902, 0.8636, 0.7925, 0.7697, 0.8246, 0.6624, 0.6458,\n",
       "                      0.8064, 0.8151, 0.8905, 0.9134, 0.8650, 0.7693, 0.7683, 0.7678, 0.7364,\n",
       "                      0.8815, 0.7457, 0.7062, 0.7141, 0.7711, 0.7967, 0.9071, 0.7803, 0.8665,\n",
       "                      0.8727, 0.7442, 0.8162, 0.9325, 0.7805, 0.7645, 0.7745, 0.6456, 0.8584,\n",
       "                      0.7061, 0.8136, 0.8105, 0.8474, 0.8668, 0.8800, 0.8739, 0.8544, 0.8094,\n",
       "                      0.8508, 0.9219, 0.7352, 0.9009, 0.9486, 0.8302, 0.8370, 0.7467, 0.7292,\n",
       "                      0.6160, 0.8350, 0.7923, 0.8225, 0.7425, 0.8324, 0.9543, 0.7463, 0.8717,\n",
       "                      0.7630, 0.8326, 0.8325, 0.7667, 0.8131, 0.8019, 0.7955, 0.8445, 0.7172,\n",
       "                      0.7918, 0.8279, 0.7783, 0.6554, 0.7447, 0.6756, 0.8131, 0.9296, 0.7699,\n",
       "                      0.8963, 0.9492, 0.7939, 0.8440, 0.8200, 0.7272, 0.8057, 0.8640, 0.8701,\n",
       "                      0.6830, 0.9092, 0.7530, 0.7789, 0.7883, 0.8672, 0.7129, 0.7086, 0.8231,\n",
       "                      0.8855, 0.7388, 0.8761, 0.7401, 0.7531, 0.8658, 0.8762, 0.6284, 0.8253,\n",
       "                      0.7792, 0.8327, 0.6993, 0.8437, 0.8320, 0.8073, 0.8199, 0.6939, 0.7515,\n",
       "                      0.7694, 0.7770, 0.8141, 0.9077, 0.7273, 0.7857, 0.7518, 0.9329, 0.8643,\n",
       "                      0.8228, 0.8154, 0.7728, 0.7720, 0.8708, 0.7639, 0.7879, 0.8191, 0.6936,\n",
       "                      0.8183, 0.7708, 0.8446, 0.8528, 0.8644, 0.8252, 0.7532, 0.8467, 0.8864,\n",
       "                      0.8590, 0.8657, 0.9056, 0.7789, 0.7626, 0.7374, 0.8323, 0.7952, 0.9017,\n",
       "                      0.7567, 0.8824, 0.8868, 0.8044, 0.8040, 0.7662, 0.8563, 0.9420, 0.7473,\n",
       "                      0.8145, 0.8943, 0.8702, 0.8092, 0.7014, 0.7288, 0.7724, 0.8030, 0.8308,\n",
       "                      0.8002, 0.8240, 0.7413, 0.8652, 0.7974, 0.9339, 0.8850, 0.8196, 0.8803,\n",
       "                      0.7508, 0.8511, 0.7208, 0.8957, 0.8634, 0.7033, 0.7358, 0.8368, 0.9133,\n",
       "                      0.7877, 0.8094, 0.8883, 0.8239, 0.8375, 0.8121, 0.8279, 0.8243, 0.7650,\n",
       "                      0.8154, 0.8931, 0.9770, 0.8351, 0.8108, 0.7038, 0.8689, 0.8745, 0.8136,\n",
       "                      0.7925, 0.8327, 0.8461, 0.7153, 0.8031, 0.7936, 0.9072, 0.8592, 0.9128,\n",
       "                      0.9358, 0.8512, 0.8170, 0.9250, 0.9144, 0.8008, 0.9058, 0.7177, 0.8999,\n",
       "                      0.7218, 0.8920, 0.8336, 0.7591, 0.7849, 0.7498, 0.8033, 0.9064, 0.8945,\n",
       "                      0.7968, 0.8058, 0.7339, 0.7722, 0.9177, 0.7573, 0.8743, 0.7550, 0.8884,\n",
       "                      0.6334, 0.8862, 0.9164, 0.8435, 0.8201, 0.7857, 0.7657, 0.7457, 0.7667,\n",
       "                      0.9246, 0.8599, 0.7610, 0.7441, 0.6960, 0.8275, 0.9557, 0.9053, 0.7673,\n",
       "                      0.8332, 0.7866, 0.6439, 0.8833, 0.7992, 0.8883, 0.8512, 0.7751, 0.8622,\n",
       "                      0.6482, 0.8979, 0.7249, 0.7999, 0.7871, 0.8173, 0.8513, 0.8142, 0.8340,\n",
       "                      0.7383, 0.8314, 0.7155, 0.7914, 0.7261, 0.8365, 0.8926, 0.7600, 0.7559,\n",
       "                      0.7831, 0.7216, 0.6700, 0.7604, 0.8424, 0.7754, 0.8322, 0.8964, 0.7617,\n",
       "                      0.8826, 0.9483, 0.8132, 0.8735, 0.8770, 0.9425, 0.8710, 0.8387, 0.7907,\n",
       "                      0.7050, 0.7986, 0.7260, 0.8396, 0.7692, 0.7643, 0.8475, 0.8888, 0.8481,\n",
       "                      0.8162, 0.8697, 0.8517, 0.8488, 0.8045, 0.8718, 0.9057, 0.8523, 0.6852,\n",
       "                      0.8969, 0.9277, 0.8727, 0.7181, 0.7761, 0.7992, 0.8634, 0.8292, 0.8301,\n",
       "                      0.6594, 0.8357, 0.7212, 0.9075, 0.7828, 0.7121, 0.7077, 0.7286, 0.8388,\n",
       "                      0.7797, 0.8393, 0.7803, 0.8426, 0.7302, 0.7735, 0.6429, 0.7313, 0.6751,\n",
       "                      0.8256, 0.9029, 0.9447, 0.8021, 0.7424, 0.7176])),\n",
       "             ('transformer.h.1.attn.c_attn.weight',\n",
       "              tensor([[-0.0391,  0.0205, -0.0089,  ..., -0.0032,  0.0138,  0.0131],\n",
       "                      [-0.0075, -0.0243, -0.0026,  ..., -0.0112,  0.0106, -0.0061],\n",
       "                      [-0.0017, -0.0261,  0.0003,  ...,  0.0059, -0.0014, -0.0050],\n",
       "                      ...,\n",
       "                      [ 0.0404, -0.0268, -0.0151,  ..., -0.0044,  0.0029,  0.0130],\n",
       "                      [ 0.0092,  0.0390,  0.0140,  ..., -0.0122,  0.0134, -0.0170],\n",
       "                      [ 0.0322,  0.0144, -0.0173,  ..., -0.0052,  0.0041,  0.0049]])),\n",
       "             ('transformer.h.1.attn.c_proj.weight',\n",
       "              tensor([[-6.3566e-03,  3.6663e-03,  5.8422e-03,  ...,  6.4057e-03,\n",
       "                        4.3613e-03, -3.4394e-03],\n",
       "                      [-1.4453e-02, -1.6357e-02,  7.7651e-04,  ...,  1.0535e-02,\n",
       "                        4.3162e-03, -2.0729e-02],\n",
       "                      [-9.3230e-03, -1.4570e-02, -1.5596e-02,  ..., -2.7650e-02,\n",
       "                        1.3970e-02, -1.3902e-02],\n",
       "                      ...,\n",
       "                      [-3.2493e-03,  1.9382e-02,  5.7190e-03,  ...,  4.7888e-02,\n",
       "                       -2.7739e-02, -1.5378e-02],\n",
       "                      [ 2.2725e-02,  4.2102e-02, -5.8863e-02,  ..., -1.0773e-02,\n",
       "                        1.1541e-05,  4.3413e-03],\n",
       "                      [ 2.5190e-03,  9.6403e-03, -2.1158e-02,  ..., -1.1448e-02,\n",
       "                        3.1752e-03, -1.2850e-02]])),\n",
       "             ('transformer.h.1.ln_2.weight',\n",
       "              tensor([0.9807, 1.0419, 0.9943, 0.9799, 1.1095, 0.9599, 1.0235, 0.9923, 1.0365,\n",
       "                      0.9714, 0.9883, 1.1020, 0.9850, 1.0054, 0.9279, 0.9988, 0.9536, 0.9489,\n",
       "                      1.0352, 0.7948, 1.0856, 1.0041, 1.0082, 0.9805, 0.8555, 0.7157, 1.0592,\n",
       "                      1.0456, 0.9972, 0.9075, 0.9772, 1.0244, 1.1465, 1.1130, 1.1273, 0.9609,\n",
       "                      0.9871, 0.9859, 0.9147, 0.8391, 1.1049, 1.0316, 1.1134, 1.0925, 0.9869,\n",
       "                      0.9444, 0.9307, 1.0624, 1.0993, 1.0682, 0.9855, 1.0438, 1.0536, 1.0858,\n",
       "                      1.1449, 1.0602, 0.9648, 0.8518, 1.0697, 1.0216, 0.9648, 0.9948, 0.9508,\n",
       "                      1.0203, 1.0076, 1.1103, 1.0396, 1.0529, 1.0280, 1.0309, 0.8574, 0.8867,\n",
       "                      0.9600, 0.9108, 1.0278, 0.8870, 0.7667, 1.0642, 1.0591, 1.0263, 1.0078,\n",
       "                      0.8778, 1.0452, 1.0246, 0.9557, 1.0912, 1.0195, 1.0460, 0.9899, 1.0748,\n",
       "                      0.9792, 1.0366, 0.9875, 0.9766, 1.0350, 1.1471, 0.9954, 0.8768, 1.1294,\n",
       "                      0.9927, 0.9589, 0.9841, 1.0874, 1.0559, 1.0474, 1.0623, 1.0002, 0.9990,\n",
       "                      1.0360, 0.8896, 1.0099, 1.0099, 1.0326, 0.9331, 0.9343, 1.0879, 1.0812,\n",
       "                      1.0132, 0.9769, 0.9968, 1.0435, 1.0078, 1.0404, 0.9971, 0.9855, 1.0626,\n",
       "                      0.9883, 0.9975, 0.9480, 1.0410, 1.0083, 0.9410, 1.0121, 1.1270, 1.1075,\n",
       "                      0.9553, 1.0502, 0.9732, 1.1244, 0.9542, 0.9728, 1.0122, 0.9903, 1.0252,\n",
       "                      1.1135, 0.8885, 1.0559, 0.8849, 1.0299, 0.9781, 0.9947, 0.8107, 0.9950,\n",
       "                      1.0855, 1.0864, 1.1189, 1.0549, 1.0520, 0.9879, 1.0719, 1.0172, 1.0199,\n",
       "                      1.0286, 1.0764, 1.0106, 1.0032, 1.0991, 1.0124, 1.0338, 0.9854, 0.9552,\n",
       "                      1.1214, 0.9798, 1.0000, 0.9812, 1.0700, 1.0048, 0.9378, 1.0298, 1.0388,\n",
       "                      1.0799, 0.9594, 1.0782, 0.9980, 1.0079, 1.1596, 1.0808, 0.7944, 1.0489,\n",
       "                      0.9647, 0.9411, 1.0502, 1.0527, 0.9387, 1.0355, 1.0232, 1.1112, 0.9798,\n",
       "                      1.0076, 1.0604, 1.1396, 0.8911, 0.9738, 0.8829, 1.0423, 1.0677, 0.9719,\n",
       "                      1.0613, 0.9231, 1.0470, 0.9057, 0.9696, 1.0408, 1.0090, 1.0679, 0.8812,\n",
       "                      1.0708, 1.0064, 1.0076, 0.9477, 0.9847, 1.0129, 0.9879, 1.0545, 0.9213,\n",
       "                      0.9313, 1.0288, 0.8529, 1.0890, 1.0252, 1.0106, 1.0368, 1.0286, 1.0041,\n",
       "                      0.9706, 1.0830, 0.9644, 1.0255, 1.1499, 0.9303, 0.8284, 1.0365, 0.8461,\n",
       "                      0.8471, 0.9844, 1.0646, 0.9429, 0.9393, 1.0870, 0.8746, 1.0313, 0.9405,\n",
       "                      0.9456, 0.9865, 1.0381, 1.0344, 0.9661, 1.0847, 0.9520, 0.9630, 0.9868,\n",
       "                      1.1018, 0.9201, 1.0258, 1.0528, 0.8955, 0.9239, 1.0137, 1.0193, 0.8430,\n",
       "                      1.1154, 0.9856, 0.9550, 1.1030, 0.9212, 0.9668, 1.0309, 0.9527, 1.0450,\n",
       "                      0.8859, 0.9112, 1.0738, 1.1041, 1.0632, 1.0506, 0.9002, 0.9511, 0.9672,\n",
       "                      0.8612, 1.0924, 1.0097, 0.9906, 1.0594, 0.9591, 0.9396, 0.9364, 0.9547,\n",
       "                      0.8463, 1.0386, 0.9707, 0.9932, 0.9445, 1.0403, 1.2230, 0.9211, 1.0184,\n",
       "                      1.1537, 1.0114, 1.1208, 1.0315, 0.9662, 1.0439, 0.9870, 0.9755, 1.0856,\n",
       "                      1.0750, 1.0056, 1.1533, 1.0443, 1.0320, 1.0253, 1.0093, 0.8550, 1.0273,\n",
       "                      0.8496, 0.8127, 1.0293, 1.0120, 1.0051, 0.6565, 0.9630, 1.0628, 1.0649,\n",
       "                      1.0528, 1.0587, 1.1113, 1.1488, 1.0075, 0.9516, 1.1007, 0.9055, 1.0989,\n",
       "                      1.0069, 0.9906, 1.0607, 1.0126, 0.9825, 1.0208, 1.0771, 1.0152, 1.0864,\n",
       "                      1.0485, 0.9454, 0.9512, 1.1022, 1.0544, 1.0354, 0.9997, 1.0481, 1.0389,\n",
       "                      0.9594, 1.1406, 1.0305, 0.9339, 1.0783, 1.0929, 1.0988, 1.0293, 0.9703,\n",
       "                      1.0273, 1.0429, 0.9639, 1.0267, 0.9862, 1.1038, 1.0630, 1.1963, 1.0521,\n",
       "                      0.9573, 0.9936, 0.8341, 1.0349, 1.0719, 1.0272])),\n",
       "             ('transformer.h.1.mlp.c_fc.weight',\n",
       "              tensor([[-0.0189,  0.0594,  0.0485,  ...,  0.0059, -0.0016,  0.0644],\n",
       "                      [-0.0006,  0.0322, -0.0048,  ...,  0.0538,  0.0108,  0.0557],\n",
       "                      [ 0.0179,  0.0153, -0.0128,  ...,  0.0269,  0.0117, -0.0883],\n",
       "                      ...,\n",
       "                      [-0.1104, -0.0279,  0.0766,  ..., -0.0441,  0.0585,  0.0135],\n",
       "                      [-0.0589,  0.0106,  0.0664,  ..., -0.0057,  0.0215,  0.0070],\n",
       "                      [-0.0344,  0.0558,  0.0702,  ..., -0.0957, -0.0573,  0.0641]])),\n",
       "             ('transformer.h.1.mlp.c_proj.weight',\n",
       "              tensor([[-0.0173,  0.0044,  0.0109,  ...,  0.0553, -0.0189,  0.0312],\n",
       "                      [ 0.0528, -0.0012, -0.0432,  ...,  0.0218, -0.0204,  0.0059],\n",
       "                      [-0.0344, -0.0024, -0.0067,  ..., -0.0079,  0.0112, -0.0029],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0526,  0.0212,  ...,  0.0094, -0.0411,  0.0153],\n",
       "                      [-0.0297, -0.0069, -0.0089,  ...,  0.0002,  0.0303, -0.0119],\n",
       "                      [ 0.0286, -0.0278, -0.0819,  ..., -0.0146, -0.0361, -0.0414]])),\n",
       "             ('transformer.h.2.ln_1.weight',\n",
       "              tensor([0.7758, 0.7586, 0.8314, 0.8125, 0.8064, 0.8966, 0.8415, 0.7869, 0.8055,\n",
       "                      0.9269, 0.9233, 0.8482, 0.8245, 0.8337, 0.7122, 0.7544, 0.8674, 0.8366,\n",
       "                      0.8068, 1.1178, 0.8508, 0.8530, 0.8496, 0.8144, 0.8317, 1.0995, 0.9214,\n",
       "                      0.7285, 0.8262, 1.0122, 0.8585, 0.7942, 0.8251, 0.8359, 0.7072, 0.6901,\n",
       "                      0.8500, 0.8320, 0.8962, 0.9653, 0.9007, 0.8039, 0.8138, 0.8365, 0.7754,\n",
       "                      0.8858, 0.7426, 0.8249, 0.7839, 0.8006, 0.8008, 0.8696, 0.7766, 0.8933,\n",
       "                      0.8496, 0.8094, 0.8179, 0.9546, 0.7915, 0.8008, 0.8111, 0.7322, 0.8570,\n",
       "                      0.7856, 0.8411, 0.8249, 0.8519, 0.8714, 0.8941, 0.8539, 0.8967, 0.8826,\n",
       "                      0.8532, 0.8944, 0.7807, 0.9224, 1.1190, 0.8212, 0.7874, 0.7374, 0.8025,\n",
       "                      0.6735, 0.8500, 0.8374, 0.8259, 0.8127, 0.8621, 0.9543, 0.7787, 0.8820,\n",
       "                      0.7570, 0.8218, 0.8199, 0.7937, 0.9084, 0.8162, 0.7821, 0.8721, 0.7445,\n",
       "                      0.8318, 0.8562, 0.8165, 0.7886, 0.7758, 0.7588, 0.8345, 0.9032, 0.7933,\n",
       "                      0.9188, 0.9910, 0.8532, 0.8385, 0.8528, 0.7629, 0.8154, 0.8891, 0.8627,\n",
       "                      0.7569, 0.9204, 0.8233, 0.8569, 0.8162, 0.8840, 0.7850, 0.7213, 0.8314,\n",
       "                      0.9056, 0.7997, 0.9104, 0.7746, 0.8000, 0.8741, 0.8690, 0.6997, 0.8423,\n",
       "                      0.7758, 0.8750, 0.6690, 0.8232, 0.8640, 0.8234, 0.8289, 0.6939, 0.8021,\n",
       "                      0.8119, 0.8211, 0.8335, 0.9077, 0.8026, 0.8104, 0.8157, 1.0768, 0.8602,\n",
       "                      0.8377, 0.8669, 0.8248, 0.8781, 0.8978, 0.7312, 0.8269, 0.8434, 0.7816,\n",
       "                      0.8026, 0.7686, 0.8421, 0.8404, 0.8383, 0.8659, 0.7751, 0.8768, 0.9012,\n",
       "                      0.8184, 0.8572, 0.9284, 0.7998, 0.7913, 0.7970, 0.7850, 0.8024, 0.8980,\n",
       "                      0.8124, 0.8668, 0.8861, 0.8105, 0.8352, 0.7576, 0.8657, 1.1424, 0.8062,\n",
       "                      0.8293, 0.8909, 0.8611, 0.8826, 0.7637, 0.7624, 0.8157, 0.8455, 0.7806,\n",
       "                      0.7933, 0.8719, 0.7899, 1.0692, 0.7685, 0.9920, 0.8789, 0.8184, 0.9118,\n",
       "                      0.8243, 0.9161, 0.8122, 1.1077, 0.8233, 0.7590, 0.8035, 0.8312, 0.9621,\n",
       "                      0.8318, 0.8019, 0.9179, 0.8558, 0.8303, 0.8914, 0.8618, 0.8229, 0.7523,\n",
       "                      0.7821, 0.8798, 1.0879, 0.8243, 0.8338, 0.8075, 0.8544, 0.8883, 0.8363,\n",
       "                      0.8025, 0.8854, 0.8219, 0.7759, 0.8207, 0.8651, 0.9954, 0.8321, 0.9594,\n",
       "                      1.0861, 0.8697, 0.8322, 0.9466, 0.9723, 0.8423, 0.9554, 0.8485, 0.9223,\n",
       "                      0.7647, 0.9127, 0.8151, 0.7814, 0.8373, 0.7561, 0.8207, 0.9185, 0.8532,\n",
       "                      0.8123, 0.8951, 0.7563, 0.8156, 0.9507, 0.7768, 0.9000, 0.8382, 0.9621,\n",
       "                      0.7027, 0.9220, 0.9538, 0.8651, 0.8103, 0.8161, 0.7656, 0.8069, 0.8052,\n",
       "                      0.9954, 0.8828, 0.8203, 0.7739, 0.7484, 0.8479, 1.0077, 0.9989, 0.7944,\n",
       "                      0.8797, 0.8424, 0.7506, 0.8796, 0.8290, 0.8874, 0.9277, 0.8263, 0.8666,\n",
       "                      0.7003, 0.9093, 0.7414, 0.8437, 0.7666, 0.8280, 0.8568, 0.8329, 0.8705,\n",
       "                      0.7899, 0.8194, 0.8299, 0.7961, 0.7367, 0.8383, 0.8933, 0.7896, 0.8029,\n",
       "                      0.8221, 0.8003, 0.7440, 0.7802, 0.8272, 0.8109, 0.8831, 0.9360, 0.7823,\n",
       "                      0.9837, 1.1574, 0.7825, 0.8967, 0.8847, 1.1577, 0.8882, 0.8326, 0.8293,\n",
       "                      0.7503, 0.8110, 0.7900, 0.8466, 0.7946, 0.7775, 0.8662, 0.9420, 0.8815,\n",
       "                      0.8091, 0.8888, 0.8481, 0.8473, 0.7966, 0.8696, 0.9036, 0.8389, 0.8004,\n",
       "                      0.9033, 0.9627, 0.8689, 0.7804, 0.8517, 0.7821, 0.8301, 0.8475, 0.8407,\n",
       "                      0.7322, 0.8403, 0.8336, 0.8889, 0.7839, 0.7851, 0.8063, 0.8632, 0.8187,\n",
       "                      0.7905, 0.8116, 0.7744, 0.8469, 0.8187, 0.8039, 0.7387, 0.7941, 0.7220,\n",
       "                      0.8330, 0.8803, 0.9993, 0.7787, 0.7689, 0.8093])),\n",
       "             ('transformer.h.2.attn.c_attn.weight',\n",
       "              tensor([[ 0.0350,  0.0525,  0.0384,  ...,  0.0282,  0.0647,  0.0161],\n",
       "                      [ 0.0064,  0.0306, -0.0276,  ..., -0.0178, -0.0234, -0.0268],\n",
       "                      [ 0.0160, -0.0009,  0.0373,  ..., -0.0492,  0.0176,  0.0293],\n",
       "                      ...,\n",
       "                      [ 0.0509, -0.0116, -0.0231,  ..., -0.0097,  0.0217, -0.0832],\n",
       "                      [ 0.0444, -0.0688, -0.0235,  ...,  0.0028, -0.0619,  0.0117],\n",
       "                      [-0.0629, -0.0613,  0.0577,  ..., -0.0102, -0.0062, -0.0658]])),\n",
       "             ('transformer.h.2.attn.c_proj.weight',\n",
       "              tensor([[ 0.0063,  0.0036,  0.0494,  ..., -0.0212, -0.0505,  0.0459],\n",
       "                      [ 0.0486, -0.0233, -0.0050,  ...,  0.0444,  0.0220,  0.0518],\n",
       "                      [ 0.0593,  0.0186,  0.0337,  ...,  0.0552, -0.0025, -0.0062],\n",
       "                      ...,\n",
       "                      [ 0.0454, -0.0291, -0.0396,  ...,  0.0352, -0.0315, -0.0406],\n",
       "                      [-0.0161,  0.0275,  0.0074,  ...,  0.0816,  0.0048,  0.0701],\n",
       "                      [ 0.0331,  0.0377,  0.0378,  ..., -0.0121, -0.0065,  0.0426]])),\n",
       "             ('transformer.h.2.ln_2.weight',\n",
       "              tensor([1.1028, 1.0847, 1.1491, 1.0106, 1.1923, 0.9754, 1.0534, 1.0698, 1.1050,\n",
       "                      0.9578, 1.0139, 1.2181, 1.0990, 1.1151, 0.9704, 1.0978, 1.0140, 1.0475,\n",
       "                      1.2043, 0.5835, 1.1878, 1.1207, 1.1157, 1.0268, 0.8801, 0.6130, 1.0937,\n",
       "                      1.2132, 1.0610, 0.8969, 1.0468, 1.1351, 1.2869, 1.3178, 1.2677, 0.9904,\n",
       "                      1.1013, 1.0571, 0.9289, 0.8323, 1.1304, 1.2222, 1.2514, 1.1592, 1.0449,\n",
       "                      0.9522, 1.0931, 1.2175, 1.2107, 1.1786, 1.0171, 1.0756, 1.1667, 1.1312,\n",
       "                      1.1776, 1.2254, 1.0566, 0.8588, 1.2083, 1.2036, 1.1398, 1.0859, 1.0725,\n",
       "                      1.0895, 1.0680, 1.2165, 1.1226, 1.0983, 1.0390, 1.1304, 0.9180, 0.9068,\n",
       "                      1.0051, 0.9492, 1.1019, 0.9126, 0.5457, 1.1688, 1.2122, 1.1727, 1.1028,\n",
       "                      0.8010, 1.1221, 1.0782, 1.0580, 1.2511, 1.1013, 1.0100, 1.1185, 1.1122,\n",
       "                      1.0470, 1.0281, 1.0903, 1.0427, 1.1837, 1.1836, 1.1341, 0.8857, 1.2181,\n",
       "                      1.0985, 1.0708, 1.1006, 1.2897, 1.0970, 1.1269, 1.1653, 1.0228, 1.1148,\n",
       "                      1.0965, 0.8354, 1.1319, 1.0823, 1.1271, 0.9627, 1.0585, 1.2567, 1.1103,\n",
       "                      1.1005, 0.9416, 1.1371, 1.1416, 1.1246, 1.0309, 1.0970, 1.0210, 1.1757,\n",
       "                      1.0743, 1.1132, 1.0031, 1.0579, 1.1236, 0.9181, 1.0920, 1.3371, 1.2482,\n",
       "                      1.0014, 1.1393, 1.1785, 1.2422, 0.9851, 1.0313, 1.0630, 1.0690, 1.1728,\n",
       "                      1.1732, 0.8533, 1.1347, 0.9357, 1.1670, 1.1462, 1.1233, 0.6580, 1.1474,\n",
       "                      1.1933, 1.2033, 1.1833, 1.1145, 1.1378, 1.0511, 1.2104, 1.0391, 1.0905,\n",
       "                      1.1932, 1.1792, 1.1193, 1.1018, 1.2192, 1.0988, 1.1345, 1.0883, 1.0076,\n",
       "                      1.2464, 1.0557, 1.0287, 1.0016, 1.1948, 1.1058, 1.0479, 1.1408, 1.0205,\n",
       "                      1.2285, 1.0272, 1.1022, 1.0320, 1.0910, 1.3641, 1.1199, 0.5439, 1.1623,\n",
       "                      1.0339, 0.9282, 1.1380, 1.1930, 1.0169, 1.1632, 1.1544, 1.1738, 1.0424,\n",
       "                      1.0922, 1.1764, 1.2269, 0.6080, 1.0703, 0.7755, 1.0907, 1.1599, 0.9541,\n",
       "                      1.1362, 1.0093, 1.0743, 0.7052, 1.0533, 1.1965, 1.1167, 1.1406, 0.8724,\n",
       "                      1.1152, 1.0795, 1.0348, 1.0190, 1.0787, 1.0992, 1.0523, 1.0415, 0.9833,\n",
       "                      0.9478, 1.1080, 0.7014, 1.2388, 1.0585, 1.1663, 1.0982, 1.0874, 1.0759,\n",
       "                      1.0721, 1.1826, 1.0985, 1.0604, 1.4592, 0.9959, 0.7846, 1.0948, 0.8362,\n",
       "                      0.7127, 1.0723, 1.2051, 0.9330, 0.9669, 1.1888, 0.8327, 1.1527, 0.9219,\n",
       "                      1.0529, 1.0014, 1.1835, 1.1416, 1.0635, 1.3247, 1.0770, 1.0134, 1.0592,\n",
       "                      1.2720, 0.9191, 1.2334, 1.2177, 0.8275, 0.9684, 1.1115, 1.1675, 0.7898,\n",
       "                      1.3161, 1.0513, 0.9862, 1.2529, 0.9616, 1.0348, 1.1036, 1.0556, 1.1679,\n",
       "                      0.8575, 1.0284, 1.1688, 1.2825, 1.1483, 1.0945, 0.7549, 0.9155, 1.0630,\n",
       "                      0.9025, 1.1704, 1.0925, 0.9549, 1.1918, 1.0452, 0.9830, 1.0311, 1.0610,\n",
       "                      0.8387, 1.0592, 1.0218, 1.1601, 1.0400, 1.1220, 1.3813, 1.0153, 1.0095,\n",
       "                      1.2896, 1.0893, 1.2208, 1.1469, 1.1079, 1.1519, 0.9919, 1.0904, 1.1640,\n",
       "                      1.1439, 1.0996, 1.3142, 1.1204, 1.0702, 1.1242, 1.1367, 0.8936, 1.1778,\n",
       "                      0.8283, 0.4747, 1.0958, 1.0839, 1.1156, 0.3548, 0.9875, 1.1394, 1.1468,\n",
       "                      1.2087, 1.1977, 1.2452, 1.2592, 1.1268, 1.0150, 1.2616, 0.8590, 1.1716,\n",
       "                      1.0431, 1.0703, 1.2256, 1.0979, 1.0739, 1.1094, 1.0851, 1.1440, 1.2051,\n",
       "                      1.0984, 0.9181, 0.9584, 1.2354, 1.2533, 1.0986, 1.0415, 1.0751, 1.0956,\n",
       "                      1.1139, 1.1245, 1.1859, 0.9697, 1.1632, 1.2412, 1.1340, 1.1473, 1.1304,\n",
       "                      1.1182, 1.0726, 1.0377, 1.1064, 1.0706, 1.1985, 1.1893, 1.4159, 1.1842,\n",
       "                      1.0457, 1.0109, 0.8103, 1.2111, 1.1715, 1.1140])),\n",
       "             ('transformer.h.2.mlp.c_fc.weight',\n",
       "              tensor([[-0.0122, -0.0209,  0.0176,  ...,  0.0104, -0.0726, -0.0329],\n",
       "                      [ 0.0520, -0.0304, -0.0344,  ..., -0.0180, -0.0384,  0.0091],\n",
       "                      [-0.0303, -0.0335, -0.0300,  ..., -0.0693, -0.0215,  0.1249],\n",
       "                      ...,\n",
       "                      [ 0.0292, -0.0172, -0.0622,  ..., -0.0045, -0.0179, -0.0365],\n",
       "                      [-0.0644,  0.0160,  0.0326,  ..., -0.0685,  0.0650,  0.0393],\n",
       "                      [ 0.0227, -0.1157, -0.0544,  ...,  0.0243, -0.0247, -0.0580]])),\n",
       "             ('transformer.h.2.mlp.c_proj.weight',\n",
       "              tensor([[-0.0306, -0.0116, -0.0182,  ..., -0.0275, -0.0021,  0.0216],\n",
       "                      [-0.0465, -0.0526, -0.0439,  ...,  0.0151,  0.0386,  0.0060],\n",
       "                      [ 0.0203, -0.0068, -0.0094,  ..., -0.0253,  0.0042,  0.0017],\n",
       "                      ...,\n",
       "                      [ 0.0161,  0.0031, -0.0037,  ...,  0.0165,  0.0654, -0.0549],\n",
       "                      [ 0.0142, -0.0106, -0.0432,  ...,  0.0097, -0.0155,  0.0003],\n",
       "                      [ 0.0031, -0.0463,  0.0422,  ..., -0.0396,  0.0126, -0.0261]])),\n",
       "             ('transformer.h.3.ln_1.weight',\n",
       "              tensor([0.9603, 0.9178, 0.9907, 0.9192, 0.9829, 0.9616, 0.9616, 0.9139, 0.9941,\n",
       "                      0.9559, 0.9872, 1.0078, 0.8937, 0.9969, 0.7613, 0.9150, 0.9369, 0.9548,\n",
       "                      0.9433, 1.1356, 0.9822, 1.0236, 0.9553, 0.9224, 0.9171, 1.1041, 0.9833,\n",
       "                      0.9169, 0.9210, 1.0417, 1.0048, 0.9677, 0.9073, 0.9716, 0.9061, 0.8311,\n",
       "                      1.0012, 0.9752, 0.9364, 0.9833, 0.9606, 0.9242, 0.9824, 1.0058, 0.9126,\n",
       "                      0.9547, 0.9083, 0.9483, 1.0276, 0.9700, 0.8888, 0.9908, 0.9281, 0.9796,\n",
       "                      0.9796, 0.9381, 0.9666, 0.9885, 0.9282, 0.9508, 0.9613, 0.7620, 0.9296,\n",
       "                      0.8935, 0.9854, 0.9258, 0.9765, 0.9399, 0.9577, 0.9270, 0.9809, 0.9469,\n",
       "                      0.9443, 0.9631, 0.8727, 0.9679, 1.1342, 0.9172, 0.9007, 0.8862, 0.9316,\n",
       "                      0.7042, 0.9597, 0.9864, 0.9380, 0.9805, 0.9764, 0.9640, 0.9492, 0.9600,\n",
       "                      0.9360, 0.9342, 0.9578, 0.9190, 1.0194, 0.9471, 0.9245, 0.9317, 0.9422,\n",
       "                      0.9599, 0.9678, 0.9496, 0.9453, 0.9648, 0.9893, 0.9433, 0.9750, 0.9489,\n",
       "                      0.9892, 1.0023, 0.9496, 0.9584, 0.9563, 0.7593, 0.9440, 0.9686, 0.9909,\n",
       "                      0.8055, 0.9656, 0.9993, 0.9955, 0.9919, 0.9369, 0.9390, 0.8501, 0.9147,\n",
       "                      0.9579, 0.9192, 0.9644, 0.8881, 0.9536, 0.9616, 0.9661, 0.9493, 1.0157,\n",
       "                      0.8383, 0.9469, 0.7956, 0.9982, 0.9003, 0.9246, 0.9353, 0.7615, 0.8999,\n",
       "                      0.9660, 0.8863, 0.9794, 0.9628, 0.9396, 0.9408, 0.9752, 1.1010, 0.9635,\n",
       "                      0.9814, 0.9947, 0.9697, 0.9971, 0.9568, 0.8543, 0.9734, 0.9620, 0.9416,\n",
       "                      0.9181, 0.9253, 0.9573, 0.9357, 0.9100, 1.0035, 0.9433, 0.9426, 0.9583,\n",
       "                      0.9426, 0.9656, 0.9678, 0.8271, 0.9864, 0.9364, 0.9375, 0.9308, 0.9431,\n",
       "                      0.9548, 0.9682, 0.9644, 0.9497, 0.9372, 0.9458, 0.9703, 1.1558, 0.9432,\n",
       "                      0.9508, 0.9602, 0.9891, 1.0065, 0.8704, 0.9233, 0.9756, 0.9324, 0.9187,\n",
       "                      0.9407, 0.9715, 0.9665, 1.1025, 0.9444, 1.0319, 0.9324, 0.9188, 0.9666,\n",
       "                      0.9902, 0.9504, 0.9329, 1.1397, 0.9202, 0.9161, 0.9650, 0.9619, 1.0011,\n",
       "                      0.9693, 0.9436, 0.9699, 0.9615, 0.9780, 0.9703, 1.0126, 0.9215, 0.9033,\n",
       "                      0.8910, 0.9418, 1.0933, 0.9466, 0.9175, 1.0144, 0.9520, 0.9394, 0.9689,\n",
       "                      0.9587, 0.9861, 0.9214, 0.9068, 0.9646, 0.8850, 1.0151, 0.9236, 0.9853,\n",
       "                      1.0961, 0.9324, 0.9859, 0.9912, 1.0012, 0.9454, 0.9860, 0.9835, 0.9774,\n",
       "                      0.9051, 0.9743, 0.9346, 0.9362, 0.9164, 0.9421, 0.9575, 0.9513, 0.9098,\n",
       "                      0.9271, 0.9584, 0.9612, 0.9732, 0.9893, 0.8780, 0.9859, 0.9298, 0.9894,\n",
       "                      0.8565, 0.9502, 0.9845, 0.9501, 0.8681, 0.9202, 0.9485, 0.9504, 0.9773,\n",
       "                      1.0538, 0.9640, 0.9965, 0.8644, 0.9757, 0.9299, 1.0077, 1.0277, 0.9404,\n",
       "                      0.9128, 1.0270, 0.9179, 0.9778, 0.9875, 0.9503, 0.9696, 0.9587, 0.9476,\n",
       "                      0.7456, 1.0024, 0.8953, 0.9215, 0.9073, 0.9563, 0.9875, 0.9043, 0.9736,\n",
       "                      0.9706, 0.9899, 0.9841, 0.9125, 0.9022, 0.9498, 0.9396, 0.9296, 0.9459,\n",
       "                      0.9714, 0.9224, 0.9077, 0.9403, 0.9349, 0.9388, 0.9644, 0.9737, 0.9615,\n",
       "                      1.0133, 1.1718, 0.8140, 0.9970, 0.9597, 1.1601, 0.9069, 0.9780, 1.0103,\n",
       "                      0.9408, 0.9855, 0.9129, 0.9226, 0.9382, 0.8822, 0.9651, 0.9841, 0.9652,\n",
       "                      0.9408, 0.9796, 0.9943, 0.9445, 0.9221, 0.9794, 0.9734, 0.9598, 0.9649,\n",
       "                      0.9810, 1.0034, 0.9685, 0.9983, 0.9290, 0.9353, 0.8948, 0.9195, 1.0053,\n",
       "                      0.9291, 0.9788, 1.0013, 0.9641, 0.8765, 0.9772, 0.9744, 0.9875, 0.9465,\n",
       "                      1.0065, 0.8624, 0.8637, 0.9576, 0.9801, 0.9658, 0.9073, 0.9256, 0.9515,\n",
       "                      0.9379, 0.9282, 1.0106, 0.8684, 0.8778, 0.9764])),\n",
       "             ('transformer.h.3.attn.c_attn.weight',\n",
       "              tensor([[ 0.0252,  0.0519,  0.0251,  ...,  0.0202,  0.0695,  0.0226],\n",
       "                      [-0.0166, -0.0219, -0.0359,  ...,  0.0039, -0.0889, -0.0252],\n",
       "                      [ 0.0103, -0.0314,  0.0036,  ...,  0.0279, -0.0248, -0.0763],\n",
       "                      ...,\n",
       "                      [ 0.0425, -0.0664, -0.0170,  ..., -0.0028,  0.0202,  0.0563],\n",
       "                      [ 0.0565, -0.0021, -0.0311,  ..., -0.0297, -0.0618,  0.0409],\n",
       "                      [-0.0036,  0.0397, -0.0735,  ..., -0.0057,  0.0505, -0.0099]])),\n",
       "             ('transformer.h.3.attn.c_proj.weight',\n",
       "              tensor([[-0.0340, -0.0112, -0.0203,  ..., -0.0258,  0.0178,  0.0238],\n",
       "                      [ 0.0158, -0.0299,  0.0127,  ..., -0.0114,  0.0298,  0.0251],\n",
       "                      [-0.0228,  0.0139,  0.0211,  ...,  0.0115, -0.0432,  0.0096],\n",
       "                      ...,\n",
       "                      [ 0.0229, -0.0023, -0.0194,  ..., -0.0270, -0.0502,  0.0089],\n",
       "                      [-0.0182, -0.0265, -0.0451,  ..., -0.0018,  0.0614, -0.0386],\n",
       "                      [ 0.0067, -0.0068, -0.0408,  ...,  0.0196,  0.0051, -0.0005]])),\n",
       "             ('transformer.h.3.ln_2.weight',\n",
       "              tensor([1.1469, 1.1381, 1.1153, 1.0523, 1.2018, 1.0697, 1.1543, 1.1317, 1.1402,\n",
       "                      1.0207, 1.0858, 1.1902, 1.1645, 1.1613, 0.9644, 1.1358, 1.0772, 1.0813,\n",
       "                      1.1968, 0.5447, 1.1890, 1.1425, 1.1034, 1.0637, 0.9372, 0.7026, 1.1605,\n",
       "                      1.1668, 1.1120, 0.8723, 1.0660, 1.1175, 1.1742, 1.2411, 1.1975, 1.0666,\n",
       "                      1.1569, 1.1110, 1.0388, 0.8023, 1.1582, 1.1826, 1.2109, 1.1989, 1.1148,\n",
       "                      1.0431, 1.0711, 1.1934, 1.2141, 1.1410, 1.1075, 1.1367, 1.1011, 1.1406,\n",
       "                      1.2311, 1.1873, 1.0798, 0.9294, 1.1784, 1.1483, 1.1287, 1.0607, 1.0580,\n",
       "                      1.1255, 1.1147, 1.1569, 1.1593, 1.1089, 1.1325, 1.1308, 0.8965, 0.9670,\n",
       "                      1.0348, 1.0566, 1.0661, 0.9813, 0.5105, 1.1085, 1.2108, 1.1754, 1.1963,\n",
       "                      0.7673, 1.1393, 1.0937, 1.1256, 1.1591, 1.1720, 1.0770, 1.1257, 1.1674,\n",
       "                      1.1082, 1.0889, 1.0686, 1.0655, 1.1584, 1.1309, 1.1468, 0.9044, 1.2135,\n",
       "                      1.1300, 1.1002, 1.1309, 1.2553, 1.1038, 1.1664, 1.1576, 1.1544, 1.1629,\n",
       "                      1.1618, 0.9774, 1.1859, 1.1051, 1.1393, 0.9111, 1.0793, 1.2154, 1.1153,\n",
       "                      1.0498, 1.0538, 1.1715, 1.1570, 1.1663, 1.0872, 1.0994, 1.0534, 1.1495,\n",
       "                      1.0701, 1.1504, 1.0564, 1.1029, 1.1480, 1.0665, 1.0899, 1.2657, 1.1979,\n",
       "                      1.0042, 1.1121, 1.0926, 1.1477, 1.0299, 1.0672, 1.1147, 1.0207, 1.1182,\n",
       "                      1.1919, 0.9282, 1.1416, 0.9498, 1.2354, 1.1189, 1.1399, 0.6791, 1.1702,\n",
       "                      1.1920, 1.1837, 1.1974, 1.1611, 1.1077, 1.0493, 1.2408, 1.1267, 1.1292,\n",
       "                      1.1229, 1.0978, 1.1249, 1.1601, 1.1963, 1.1586, 1.1604, 1.1300, 1.0483,\n",
       "                      1.1685, 1.1105, 1.1401, 0.9762, 1.1876, 1.1239, 1.1000, 1.1172, 1.1050,\n",
       "                      1.2038, 1.0838, 1.1253, 1.1132, 1.1618, 1.2554, 1.1701, 0.5230, 1.1526,\n",
       "                      1.0630, 1.0089, 1.2151, 1.1546, 1.0701, 1.1736, 1.1416, 1.1936, 1.0729,\n",
       "                      1.1558, 1.1500, 1.2077, 0.5690, 1.0831, 0.9492, 1.0293, 1.0986, 1.0233,\n",
       "                      1.1643, 1.0277, 1.1245, 0.6983, 1.0809, 1.1540, 1.1594, 1.1644, 0.9809,\n",
       "                      1.1809, 1.1156, 1.1002, 1.0575, 1.1152, 1.1192, 1.0888, 1.1137, 1.0324,\n",
       "                      1.0040, 1.1381, 0.7237, 1.2646, 1.0976, 1.1443, 1.1441, 1.0580, 1.1647,\n",
       "                      1.0727, 1.2200, 1.1447, 1.0296, 1.3465, 1.0368, 0.8704, 1.1137, 0.9924,\n",
       "                      0.7135, 1.0875, 1.2027, 1.0057, 1.0328, 1.1683, 0.9419, 1.1431, 1.0832,\n",
       "                      1.0729, 1.0773, 1.1620, 1.1701, 1.1456, 1.1779, 1.0954, 1.0326, 1.0297,\n",
       "                      1.1873, 1.0316, 1.2076, 1.2069, 0.9467, 0.9958, 1.2129, 1.1431, 0.8514,\n",
       "                      1.2062, 1.1038, 0.9902, 1.2291, 1.0288, 1.0382, 1.1434, 1.1009, 1.1531,\n",
       "                      0.8329, 1.0662, 1.1502, 1.2293, 1.1094, 1.1493, 0.8505, 0.8984, 1.1070,\n",
       "                      0.8799, 1.1877, 1.1574, 1.0647, 1.1968, 1.1027, 0.9696, 1.0704, 1.0326,\n",
       "                      0.8207, 1.0980, 1.0654, 1.1211, 1.0884, 1.1267, 1.3215, 1.0044, 1.1270,\n",
       "                      1.2246, 1.1665, 1.1963, 1.1167, 1.0561, 1.1772, 1.0922, 1.1268, 1.2015,\n",
       "                      1.2036, 1.1013, 1.2210, 1.1935, 1.1233, 1.1961, 1.1152, 0.9316, 1.1311,\n",
       "                      0.8520, 0.4671, 1.0906, 1.1822, 1.1190, 0.4506, 1.0296, 1.1920, 1.1291,\n",
       "                      1.2076, 1.1890, 1.1901, 1.1819, 1.1540, 1.0417, 1.2182, 1.0238, 1.1695,\n",
       "                      1.1285, 1.1015, 1.2136, 1.1311, 1.0409, 1.1245, 1.1350, 1.1400, 1.2247,\n",
       "                      1.1454, 1.0283, 1.0766, 1.2224, 1.1754, 1.0800, 1.0899, 1.1194, 1.1176,\n",
       "                      1.0900, 1.1367, 1.1667, 1.0750, 1.1243, 1.2403, 1.1943, 1.1555, 1.1107,\n",
       "                      1.1421, 1.1063, 1.0504, 1.1229, 1.1164, 1.1884, 1.0938, 1.2840, 1.1774,\n",
       "                      1.1014, 1.1041, 0.9069, 1.1422, 1.1884, 1.1252])),\n",
       "             ('transformer.h.3.mlp.c_fc.weight',\n",
       "              tensor([[ 0.0213,  0.0816, -0.0017,  ...,  0.0185, -0.0582, -0.0160],\n",
       "                      [-0.0397,  0.0119, -0.0168,  ...,  0.0161,  0.0217, -0.0037],\n",
       "                      [-0.0306, -0.0183, -0.0098,  ...,  0.0009,  0.0183,  0.0065],\n",
       "                      ...,\n",
       "                      [-0.0186, -0.0318, -0.0379,  ..., -0.0180,  0.0537,  0.0350],\n",
       "                      [ 0.0712,  0.0632, -0.0146,  ..., -0.0028,  0.1149,  0.0003],\n",
       "                      [-0.0080,  0.0072,  0.0015,  ..., -0.1313,  0.0186,  0.0486]])),\n",
       "             ('transformer.h.3.mlp.c_proj.weight',\n",
       "              tensor([[-0.0411,  0.0041, -0.0027,  ...,  0.0313, -0.0083, -0.0065],\n",
       "                      [ 0.0235,  0.0034,  0.0280,  ..., -0.0014,  0.0075, -0.0546],\n",
       "                      [ 0.0110, -0.0042,  0.0405,  ...,  0.0195, -0.0240,  0.0034],\n",
       "                      ...,\n",
       "                      [ 0.0509, -0.0114, -0.0102,  ...,  0.0339, -0.0206,  0.1183],\n",
       "                      [-0.0062, -0.0021,  0.0211,  ..., -0.0392,  0.0954, -0.0243],\n",
       "                      [-0.0250,  0.0024,  0.0034,  ...,  0.0059, -0.0375,  0.0094]])),\n",
       "             ('transformer.h.4.ln_1.weight',\n",
       "              tensor([1.0941, 1.0839, 1.0939, 1.0728, 1.1201, 1.1051, 1.2288, 1.0826, 1.1332,\n",
       "                      1.0327, 1.0465, 1.1794, 1.0396, 1.1638, 0.8648, 1.0620, 1.0721, 1.0978,\n",
       "                      1.1128, 1.0471, 1.1827, 1.1665, 1.1326, 1.1104, 1.0044, 1.0435, 1.0980,\n",
       "                      1.1539, 1.0843, 0.9910, 1.1358, 1.1827, 1.0757, 1.1027, 1.1103, 1.0348,\n",
       "                      1.1235, 1.1296, 1.0209, 0.9735, 1.0757, 1.0981, 1.1146, 1.1887, 1.1148,\n",
       "                      1.0890, 1.1062, 1.1129, 1.2160, 1.1346, 1.0607, 1.1458, 1.0838, 1.0991,\n",
       "                      1.1545, 1.1197, 1.1162, 1.0263, 1.0817, 1.0755, 1.1219, 1.0171, 1.0769,\n",
       "                      1.1454, 1.1482, 1.0449, 1.1516, 1.0800, 1.1115, 1.1153, 1.0078, 0.9969,\n",
       "                      1.0683, 1.0945, 1.0508, 1.0305, 1.0341, 1.1081, 1.0464, 1.0799, 1.0443,\n",
       "                      0.7394, 1.0982, 1.0925, 1.1226, 1.0807, 1.1433, 1.0430, 1.0981, 1.1445,\n",
       "                      1.1318, 1.1982, 1.0550, 1.0706, 1.1165, 1.1039, 1.0649, 0.9803, 1.1359,\n",
       "                      1.0691, 1.1144, 1.1292, 1.1290, 1.1129, 1.1779, 1.1109, 1.1331, 1.1195,\n",
       "                      1.0995, 1.0444, 1.1210, 1.1567, 1.1042, 0.8394, 1.0859, 1.0777, 1.1292,\n",
       "                      0.9705, 1.0114, 1.1227, 1.1805, 1.1821, 1.0287, 1.0722, 1.0137, 1.0678,\n",
       "                      1.0785, 1.1372, 1.0210, 1.0487, 1.1165, 1.0930, 1.1041, 1.1072, 1.1483,\n",
       "                      1.0279, 1.0883, 0.9891, 1.1371, 0.9365, 1.0675, 1.1399, 0.8477, 1.0947,\n",
       "                      1.1794, 1.0209, 1.1575, 1.0468, 1.0528, 1.1150, 1.1372, 1.0335, 1.1160,\n",
       "                      1.1536, 1.1606, 1.0797, 1.1351, 1.0282, 0.9833, 1.1509, 1.1201, 1.0705,\n",
       "                      1.0659, 1.0963, 1.1238, 1.1570, 1.0536, 1.1924, 1.1166, 1.1186, 1.0550,\n",
       "                      1.0979, 1.1089, 1.1354, 0.9034, 1.1430, 1.1100, 1.1300, 1.0492, 1.0713,\n",
       "                      1.1052, 1.1018, 1.1428, 1.1372, 1.1283, 1.1450, 1.1631, 1.0394, 1.1171,\n",
       "                      1.1137, 1.1156, 1.1633, 1.1225, 1.0657, 1.1180, 1.1214, 1.0688, 1.0675,\n",
       "                      1.0752, 1.1003, 1.1282, 0.9685, 1.1194, 1.0656, 1.0790, 1.0963, 1.0274,\n",
       "                      1.1676, 0.9820, 1.1081, 1.1230, 1.1269, 1.0786, 1.1205, 1.1604, 1.0598,\n",
       "                      1.1092, 1.0941, 1.0901, 1.0680, 1.1575, 1.1122, 1.0952, 1.0807, 1.0802,\n",
       "                      0.9945, 1.0635, 1.0158, 1.1450, 1.0749, 1.1503, 1.1066, 1.0942, 1.1460,\n",
       "                      1.0574, 1.1509, 1.0725, 1.0773, 1.1236, 0.9601, 1.0305, 1.0089, 1.0319,\n",
       "                      1.0405, 1.0090, 1.1577, 1.0135, 1.0511, 1.1114, 1.0031, 1.1395, 1.0955,\n",
       "                      1.0896, 1.0793, 1.0964, 1.1528, 1.1054, 1.1440, 1.0749, 1.0020, 1.0249,\n",
       "                      1.0538, 1.0449, 1.1226, 1.1620, 1.0759, 0.9959, 1.1248, 1.0420, 1.0179,\n",
       "                      1.0929, 1.0509, 1.0141, 1.0931, 1.0610, 1.0622, 1.1475, 1.1123, 1.1598,\n",
       "                      1.0630, 1.1097, 1.1532, 1.0667, 1.1848, 1.0902, 0.9939, 1.0310, 1.1263,\n",
       "                      0.9348, 1.1909, 1.1487, 1.0908, 1.1549, 1.0587, 1.0352, 1.1148, 1.0381,\n",
       "                      0.7873, 1.1163, 1.0588, 1.0196, 1.0496, 1.0844, 1.1133, 1.0618, 1.0986,\n",
       "                      1.2332, 1.1344, 1.1646, 1.0484, 1.0762, 1.1040, 1.0734, 1.0939, 1.0630,\n",
       "                      1.1561, 1.1430, 1.1530, 1.1103, 1.1152, 1.0852, 1.1159, 1.0272, 1.1214,\n",
       "                      1.0370, 1.0548, 0.9654, 1.1451, 1.1295, 1.0463, 0.9903, 1.1036, 1.1753,\n",
       "                      1.1797, 1.1902, 1.0637, 1.0591, 1.0871, 1.0238, 1.1515, 1.0710, 1.0619,\n",
       "                      1.1908, 1.0893, 1.1490, 1.1375, 1.0655, 1.1346, 1.0651, 1.0952, 1.1254,\n",
       "                      1.1877, 1.0892, 1.0807, 1.1502, 1.0842, 1.0682, 1.0835, 1.0366, 1.2002,\n",
       "                      1.1049, 1.1463, 1.1550, 1.0840, 1.0225, 1.1379, 1.1571, 1.1788, 1.0837,\n",
       "                      1.1629, 0.9949, 1.0080, 1.0820, 1.0852, 1.0987, 1.0937, 1.1479, 1.1217,\n",
       "                      1.1269, 1.1083, 1.0255, 1.0113, 1.1121, 1.1300])),\n",
       "             ('transformer.h.4.attn.c_attn.weight',\n",
       "              tensor([[-0.0333, -0.0441, -0.0177,  ...,  0.0603, -0.0555, -0.0012],\n",
       "                      [-0.0263, -0.0278, -0.1042,  ..., -0.0412, -0.0826, -0.1209],\n",
       "                      [ 0.0672, -0.0286, -0.0592,  ..., -0.0824,  0.0384,  0.0781],\n",
       "                      ...,\n",
       "                      [ 0.0361,  0.0759, -0.0163,  ...,  0.0118, -0.0059, -0.0270],\n",
       "                      [ 0.0169,  0.0052,  0.0185,  ...,  0.0223,  0.0411, -0.0016],\n",
       "                      [ 0.0222, -0.0630,  0.0535,  ...,  0.0414,  0.0243, -0.0269]])),\n",
       "             ('transformer.h.4.attn.c_proj.weight',\n",
       "              tensor([[ 0.0209,  0.0081,  0.0084,  ..., -0.0281, -0.0661, -0.0052],\n",
       "                      [ 0.0201,  0.0731, -0.0478,  ...,  0.0145,  0.0133, -0.0302],\n",
       "                      [ 0.0166, -0.0352, -0.0128,  ...,  0.0248,  0.0445,  0.0191],\n",
       "                      ...,\n",
       "                      [-0.0305, -0.0043,  0.0064,  ...,  0.0392, -0.0143, -0.0094],\n",
       "                      [-0.0065,  0.0225, -0.0338,  ...,  0.0347, -0.0049, -0.0347],\n",
       "                      [-0.0306,  0.0385,  0.0245,  ...,  0.0338, -0.0232, -0.0149]])),\n",
       "             ('transformer.h.4.ln_2.weight',\n",
       "              tensor([1.2256, 1.1974, 1.1688, 1.1533, 1.2742, 1.1551, 1.2314, 1.2148, 1.2185,\n",
       "                      1.2651, 1.1855, 1.2210, 1.2322, 1.2304, 1.0264, 1.1743, 1.1629, 1.1689,\n",
       "                      1.1896, 0.6968, 1.1811, 1.2178, 1.1749, 1.1718, 1.0448, 0.9634, 1.2678,\n",
       "                      1.2516, 1.2243, 0.8979, 1.1594, 1.2053, 1.2317, 1.3128, 1.2309, 1.1470,\n",
       "                      1.2831, 1.1891, 1.1728, 1.0070, 1.2090, 1.2611, 1.2175, 1.1901, 1.1991,\n",
       "                      1.1661, 1.1477, 1.2570, 1.2625, 1.2603, 1.1697, 1.2356, 1.1247, 1.2376,\n",
       "                      1.2869, 1.2142, 1.1753, 1.0997, 1.1957, 1.1936, 1.2161, 1.1089, 1.0803,\n",
       "                      1.2201, 1.1386, 1.1938, 1.2130, 1.1609, 1.2042, 1.2087, 1.0420, 1.0916,\n",
       "                      1.1636, 1.1731, 1.1312, 1.1467, 0.6787, 1.1686, 1.3431, 1.2422, 1.2489,\n",
       "                      0.7852, 1.2519, 1.1731, 1.1986, 1.2441, 1.2452, 1.1549, 1.1907, 1.1771,\n",
       "                      1.1810, 1.1606, 1.1945, 1.1490, 1.2284, 1.2369, 1.2404, 1.0559, 1.2315,\n",
       "                      1.2327, 1.1757, 1.1655, 1.2449, 1.2221, 1.2939, 1.1797, 1.2024, 1.2251,\n",
       "                      1.2397, 1.1352, 1.2524, 1.1473, 1.2005, 0.9910, 1.1190, 1.2633, 1.2267,\n",
       "                      1.1079, 1.1729, 1.2262, 1.2004, 1.2035, 1.1438, 1.1358, 1.1033, 1.2765,\n",
       "                      1.1870, 1.2029, 1.1300, 1.1558, 1.2390, 1.1827, 1.1648, 1.3504, 1.2050,\n",
       "                      1.1034, 1.2128, 1.1907, 1.1756, 1.1253, 1.1799, 1.1667, 1.0542, 1.1703,\n",
       "                      1.1913, 1.0516, 1.1936, 1.1241, 1.2693, 1.1758, 1.1843, 0.8849, 1.2083,\n",
       "                      1.2431, 1.1987, 1.2489, 1.2247, 1.1730, 1.0603, 1.2500, 1.2195, 1.2245,\n",
       "                      1.2053, 1.1648, 1.1852, 1.2304, 1.2326, 1.2445, 1.1629, 1.1574, 1.1516,\n",
       "                      1.2618, 1.1830, 1.1938, 1.0290, 1.2779, 1.2545, 1.1406, 1.2131, 1.1576,\n",
       "                      1.2687, 1.1872, 1.1894, 1.1874, 1.2184, 1.2366, 1.1920, 0.7165, 1.2391,\n",
       "                      1.1075, 1.1735, 1.2841, 1.2053, 1.1490, 1.2034, 1.1682, 1.2754, 1.1792,\n",
       "                      1.2789, 1.2159, 1.2339, 0.6765, 1.1628, 1.1023, 1.2122, 1.2104, 1.1206,\n",
       "                      1.2168, 1.0703, 1.1339, 0.8530, 1.1255, 1.2370, 1.2484, 1.2088, 1.1600,\n",
       "                      1.2878, 1.1621, 1.2100, 1.1514, 1.1755, 1.1485, 1.1616, 1.1937, 1.1187,\n",
       "                      1.0934, 1.1905, 0.9271, 1.3346, 1.1961, 1.2082, 1.2042, 1.1743, 1.1786,\n",
       "                      1.1239, 1.2856, 1.2577, 1.1454, 1.2650, 1.1534, 1.0044, 1.1553, 1.1045,\n",
       "                      0.8801, 1.1667, 1.2330, 1.1718, 1.1507, 1.2409, 1.0753, 1.2685, 1.1952,\n",
       "                      1.1513, 1.1960, 1.1986, 1.2243, 1.1800, 1.1979, 1.2154, 1.1365, 1.1194,\n",
       "                      1.1999, 1.1434, 1.2215, 1.2423, 1.1485, 1.0765, 1.2671, 1.1580, 1.0470,\n",
       "                      1.2451, 1.1362, 1.0977, 1.2210, 1.1604, 1.1899, 1.2047, 1.1225, 1.1927,\n",
       "                      0.9983, 1.1183, 1.1589, 1.1831, 1.0796, 1.2085, 0.9983, 1.0695, 1.1386,\n",
       "                      0.9845, 1.1772, 1.2233, 1.2132, 1.1777, 1.1617, 1.1424, 1.1392, 1.1711,\n",
       "                      0.7833, 1.2105, 1.1172, 1.2279, 1.1659, 1.1422, 1.2948, 1.0436, 1.1989,\n",
       "                      1.2231, 1.2316, 1.2758, 1.2795, 1.1613, 1.2122, 1.1268, 1.1639, 1.2381,\n",
       "                      1.1891, 1.1806, 1.3023, 1.2691, 1.2222, 1.2701, 1.2309, 1.0629, 1.1514,\n",
       "                      1.0225, 0.6053, 1.1556, 1.2353, 1.1444, 0.5053, 1.0697, 1.2066, 1.1589,\n",
       "                      1.2419, 1.2037, 1.1429, 1.2530, 1.1913, 1.0406, 1.2225, 1.1633, 1.2096,\n",
       "                      1.1849, 1.2294, 1.2384, 1.1997, 1.1822, 1.1972, 1.2505, 1.1908, 1.3182,\n",
       "                      1.2346, 1.1399, 1.1445, 1.2121, 1.2626, 1.1435, 1.1754, 1.2311, 1.2272,\n",
       "                      1.1807, 1.1706, 1.2308, 1.2384, 1.1626, 1.2549, 1.1678, 1.2804, 1.1507,\n",
       "                      1.1828, 1.1751, 1.1260, 1.1832, 1.1652, 1.2039, 1.1750, 1.2677, 1.2373,\n",
       "                      1.1790, 1.1978, 1.0552, 1.2339, 1.1690, 1.2059])),\n",
       "             ('transformer.h.4.mlp.c_fc.weight',\n",
       "              tensor([[-0.0265,  0.0090,  0.0291,  ..., -0.1453, -0.0240,  0.0199],\n",
       "                      [-0.0042, -0.0083, -0.0119,  ..., -0.0354,  0.0381, -0.0170],\n",
       "                      [ 0.0319,  0.1227, -0.0127,  ..., -0.0397,  0.1241,  0.0349],\n",
       "                      ...,\n",
       "                      [-0.0065, -0.0094, -0.0176,  ..., -0.0097,  0.0423,  0.0005],\n",
       "                      [-0.0108,  0.0499,  0.0366,  ...,  0.0323,  0.0526,  0.0665],\n",
       "                      [ 0.0781,  0.0126,  0.0117,  ..., -0.0164, -0.0159,  0.0098]])),\n",
       "             ('transformer.h.4.mlp.c_proj.weight',\n",
       "              tensor([[-0.0352,  0.0139,  0.0390,  ..., -0.0829, -0.0341, -0.0487],\n",
       "                      [-0.0107, -0.0391, -0.0341,  ...,  0.0153,  0.0198,  0.0711],\n",
       "                      [ 0.0521,  0.0289, -0.0268,  ...,  0.0293,  0.0287,  0.1050],\n",
       "                      ...,\n",
       "                      [-0.0861, -0.0164, -0.0274,  ..., -0.0189,  0.0473,  0.0243],\n",
       "                      [ 0.0209, -0.0212,  0.0073,  ..., -0.0007, -0.0844,  0.0320],\n",
       "                      [ 0.0110,  0.0601,  0.0059,  ..., -0.0312, -0.0081,  0.0169]])),\n",
       "             ('transformer.h.5.ln_1.weight',\n",
       "              tensor([1.1654, 1.1363, 1.1788, 1.1051, 1.1812, 1.1272, 1.2244, 1.1792, 1.1444,\n",
       "                      1.0960, 1.1931, 1.1505, 1.1490, 1.2131, 0.8841, 1.2175, 1.1796, 1.2117,\n",
       "                      1.2119, 0.9161, 1.1683, 1.2110, 1.2053, 1.1763, 1.0575, 1.0966, 1.2307,\n",
       "                      1.2295, 1.2096, 0.9424, 1.2055, 1.1636, 1.1691, 1.2177, 1.2057, 1.1300,\n",
       "                      1.2210, 1.2022, 1.1876, 1.0149, 1.1125, 1.2077, 1.1628, 1.1568, 1.1943,\n",
       "                      1.1408, 1.2303, 1.1849, 1.1507, 1.2146, 1.2080, 1.1888, 1.1560, 1.1724,\n",
       "                      1.2257, 1.1785, 1.1984, 1.1165, 1.1641, 1.0869, 1.1951, 1.0592, 1.1866,\n",
       "                      1.1842, 1.1659, 1.0893, 1.1683, 1.1711, 1.1987, 1.1757, 1.0615, 1.0318,\n",
       "                      1.1751, 1.1995, 1.0559, 1.1033, 0.8490, 1.1918, 1.1011, 1.1435, 1.1424,\n",
       "                      0.7951, 1.2174, 1.1949, 1.1509, 1.2133, 1.2153, 1.1575, 1.1880, 1.1991,\n",
       "                      1.2374, 1.1717, 1.1226, 1.0629, 1.2256, 1.2361, 1.1980, 1.0857, 1.1997,\n",
       "                      1.1919, 1.2273, 1.1414, 1.2071, 1.1949, 1.1562, 1.1642, 1.1912, 1.2094,\n",
       "                      1.1953, 1.1072, 1.1840, 1.1884, 1.1863, 0.9117, 1.2027, 1.2183, 1.2071,\n",
       "                      0.9966, 1.0941, 1.2237, 1.2264, 1.2270, 1.0893, 1.1626, 1.0750, 1.1699,\n",
       "                      1.1934, 1.1706, 1.1271, 1.1486, 1.1444, 1.1914, 1.2096, 1.2399, 1.1791,\n",
       "                      1.0993, 1.1497, 1.1026, 1.1316, 0.9331, 1.1939, 1.1827, 0.8747, 1.1760,\n",
       "                      1.1901, 1.1014, 1.1771, 1.1754, 1.1561, 1.1414, 1.2109, 1.0052, 1.2177,\n",
       "                      1.1914, 1.1676, 1.2403, 1.2023, 1.0950, 1.0024, 1.2364, 1.1696, 1.1666,\n",
       "                      1.1170, 1.0626, 1.1986, 1.2329, 1.1228, 1.2280, 1.1506, 1.1194, 1.1915,\n",
       "                      1.2079, 1.1674, 1.2074, 0.9067, 1.2127, 1.1918, 1.1610, 1.2692, 1.1698,\n",
       "                      1.1762, 1.1658, 1.2001, 1.2006, 1.2095, 1.2040, 1.1948, 0.8248, 1.2234,\n",
       "                      1.1313, 1.2631, 1.1857, 1.1289, 1.1221, 1.2115, 1.1340, 1.1635, 1.1251,\n",
       "                      1.2130, 1.2193, 1.2325, 0.8256, 1.1426, 1.1295, 1.1938, 1.1829, 1.1246,\n",
       "                      1.2041, 1.0151, 1.1416, 0.9394, 1.1790, 1.2382, 1.2464, 1.1802, 1.2007,\n",
       "                      1.1696, 1.2064, 1.1760, 1.1650, 1.1377, 1.1651, 1.1390, 1.1684, 1.2239,\n",
       "                      1.1442, 1.1193, 1.0064, 1.2418, 1.0937, 1.2089, 1.2058, 1.1680, 1.1147,\n",
       "                      1.1603, 1.2226, 1.1804, 1.0985, 1.2249, 1.0264, 1.0092, 1.1405, 1.1748,\n",
       "                      1.0047, 1.0952, 1.1589, 1.0539, 1.1206, 1.1771, 1.1066, 1.2188, 1.1906,\n",
       "                      1.2028, 1.1781, 1.2124, 1.2248, 1.1462, 1.2181, 1.1852, 1.1528, 1.1997,\n",
       "                      1.1429, 1.0934, 1.2044, 1.2145, 1.1508, 1.0826, 1.1609, 1.1436, 1.0361,\n",
       "                      1.2435, 1.1263, 1.1223, 1.1805, 1.1276, 1.1681, 1.2042, 1.1127, 1.1294,\n",
       "                      1.1095, 1.1175, 1.2128, 1.1197, 1.1207, 1.1617, 1.0603, 1.0853, 1.1601,\n",
       "                      0.9849, 1.1895, 1.1726, 1.1914, 1.1973, 1.1617, 1.0947, 1.1951, 1.2103,\n",
       "                      0.7859, 1.1655, 1.1551, 1.1100, 1.1645, 1.0855, 1.2316, 1.0688, 1.2185,\n",
       "                      1.2208, 1.1952, 1.1700, 1.1563, 1.1779, 1.2031, 1.1653, 1.1791, 1.0974,\n",
       "                      1.0805, 1.2169, 1.2436, 1.1780, 1.1780, 1.1632, 1.2102, 1.1208, 1.2290,\n",
       "                      1.0676, 0.8631, 1.0154, 1.2024, 1.2044, 0.8050, 0.9317, 1.1803, 1.1647,\n",
       "                      1.2556, 1.1991, 1.0867, 1.1278, 1.1552, 1.0246, 1.1456, 1.1522, 1.2154,\n",
       "                      1.1928, 1.2306, 1.2349, 1.1887, 1.1719, 1.2396, 1.1921, 1.1714, 1.1606,\n",
       "                      1.2039, 1.1916, 1.1289, 1.1170, 1.1690, 1.1205, 1.1429, 1.1944, 1.1835,\n",
       "                      1.2527, 1.1562, 1.2643, 1.1427, 1.0872, 1.1508, 1.1945, 1.2010, 1.1452,\n",
       "                      1.1726, 1.0669, 1.0678, 1.1712, 1.1747, 1.1731, 1.1797, 1.1744, 1.2109,\n",
       "                      1.2217, 1.1402, 1.0855, 1.1643, 1.1801, 1.2261])),\n",
       "             ('transformer.h.5.attn.c_attn.weight',\n",
       "              tensor([[ 0.1182,  0.0206, -0.0550,  ...,  0.0360, -0.0130,  0.0206],\n",
       "                      [ 0.0346,  0.0402, -0.0592,  ...,  0.1157,  0.0362,  0.0012],\n",
       "                      [-0.0056,  0.0076,  0.0131,  ..., -0.0155, -0.0160,  0.0857],\n",
       "                      ...,\n",
       "                      [ 0.0380, -0.0736, -0.0578,  ..., -0.0182,  0.0082,  0.1417],\n",
       "                      [-0.0439, -0.0157,  0.0281,  ...,  0.0071,  0.1097, -0.0392],\n",
       "                      [-0.0199, -0.0016, -0.0322,  ...,  0.0724,  0.0343,  0.0197]])),\n",
       "             ('transformer.h.5.attn.c_proj.weight',\n",
       "              tensor([[ 0.0165, -0.0148,  0.0024,  ..., -0.0030,  0.0065, -0.0032],\n",
       "                      [-0.0226,  0.0432, -0.0077,  ..., -0.0446, -0.0290, -0.0552],\n",
       "                      [ 0.0286,  0.0017, -0.0404,  ..., -0.0434, -0.0375,  0.0226],\n",
       "                      ...,\n",
       "                      [ 0.0278,  0.0419, -0.0337,  ...,  0.0554,  0.0401, -0.0581],\n",
       "                      [ 0.0163, -0.0100,  0.0240,  ..., -0.0017,  0.0642, -0.0208],\n",
       "                      [ 0.0522,  0.0533, -0.0773,  ...,  0.0399, -0.0239, -0.0467]])),\n",
       "             ('transformer.h.5.ln_2.weight',\n",
       "              tensor([1.2415, 1.2734, 1.2278, 1.1538, 1.2547, 1.2182, 1.1735, 1.2518, 1.2056,\n",
       "                      1.2568, 1.1797, 1.1881, 1.2798, 1.2550, 1.0593, 1.2841, 1.2695, 1.2536,\n",
       "                      1.3246, 0.8300, 1.2314, 1.2843, 1.2857, 1.1809, 1.1153, 0.9906, 1.2399,\n",
       "                      1.2362, 1.2625, 1.0047, 1.2441, 1.1663, 1.2881, 1.2619, 1.2722, 1.2225,\n",
       "                      1.2773, 1.2632, 1.1885, 1.0473, 1.2008, 1.2763, 1.2284, 1.1748, 1.2045,\n",
       "                      1.2078, 1.2596, 1.2110, 1.3048, 1.2825, 1.2270, 1.2070, 1.2391, 1.2705,\n",
       "                      1.2340, 1.2435, 1.2372, 1.2345, 1.2937, 1.2337, 1.2623, 1.2747, 1.1418,\n",
       "                      1.2088, 1.2546, 1.2472, 1.2210, 1.2805, 1.2080, 1.2049, 1.1066, 1.1968,\n",
       "                      1.1856, 1.2647, 1.2352, 1.2409, 0.8294, 1.2040, 1.3196, 1.2346, 1.2805,\n",
       "                      0.7711, 1.2456, 1.2747, 1.2409, 1.2810, 1.2604, 1.2047, 1.3140, 1.2684,\n",
       "                      1.2487, 1.1867, 1.2472, 1.1705, 1.2619, 1.2739, 1.2953, 1.2073, 1.3203,\n",
       "                      1.2240, 1.2010, 1.2637, 1.3306, 1.2068, 1.2464, 1.2538, 1.2237, 1.2670,\n",
       "                      1.2641, 1.1898, 1.2402, 1.2277, 1.2748, 1.0852, 1.2038, 1.2567, 1.2076,\n",
       "                      1.0879, 1.2758, 1.2154, 1.2030, 1.2449, 1.1781, 1.2465, 1.1504, 1.3036,\n",
       "                      1.2591, 1.2583, 1.1668, 1.2696, 1.2825, 1.1793, 1.1705, 1.3253, 1.2442,\n",
       "                      1.1723, 1.1982, 1.2174, 1.2259, 1.0508, 1.2318, 1.2785, 0.9634, 1.1704,\n",
       "                      1.1884, 1.1371, 1.2063, 1.1938, 1.3157, 1.2843, 1.2727, 0.8881, 1.2457,\n",
       "                      1.2176, 1.2296, 1.1864, 1.2585, 1.2589, 1.1454, 1.2458, 1.2610, 1.2618,\n",
       "                      1.1956, 1.1819, 1.2272, 1.2008, 1.2349, 1.2766, 1.2250, 1.1718, 1.2306,\n",
       "                      1.2475, 1.2229, 1.1456, 1.0973, 1.1838, 1.2185, 1.2138, 1.2651, 1.2067,\n",
       "                      1.2472, 1.2291, 1.2520, 1.2357, 1.2132, 1.2171, 1.1649, 0.6462, 1.2592,\n",
       "                      1.1853, 1.2173, 1.2974, 1.3108, 1.2337, 1.2678, 1.2497, 1.2953, 1.2541,\n",
       "                      1.2360, 1.1877, 1.2529, 0.5443, 1.2371, 1.0679, 1.2733, 1.2208, 1.1822,\n",
       "                      1.2881, 1.1968, 1.2674, 0.8902, 1.2084, 1.2698, 1.2319, 1.1793, 1.2538,\n",
       "                      1.1779, 1.1869, 1.1956, 1.3442, 1.2546, 1.2200, 1.2228, 1.2779, 1.1538,\n",
       "                      1.2048, 1.2197, 0.9765, 1.2367, 1.2281, 1.1967, 1.2204, 1.2362, 1.2247,\n",
       "                      1.1355, 1.2623, 1.2798, 1.1306, 1.2558, 1.1812, 1.0986, 1.2136, 1.1906,\n",
       "                      0.9961, 1.2997, 1.2006, 1.1598, 1.0889, 1.2788, 1.1853, 1.2166, 1.2234,\n",
       "                      1.2611, 1.2621, 1.2379, 1.3290, 1.1947, 1.2678, 1.2204, 1.2699, 1.2453,\n",
       "                      1.2555, 1.2361, 1.3371, 1.2775, 1.2068, 1.1901, 1.3199, 1.2760, 1.0854,\n",
       "                      1.2944, 1.2868, 1.2380, 1.2348, 1.2311, 1.2246, 1.2311, 1.1599, 1.2763,\n",
       "                      1.0281, 1.2410, 1.2205, 1.2658, 1.1948, 1.2656, 1.1261, 1.0320, 1.1812,\n",
       "                      1.1597, 1.1530, 1.3009, 1.2652, 1.3124, 1.2615, 1.1401, 1.1576, 1.1949,\n",
       "                      0.8930, 1.2342, 1.1849, 1.2797, 1.2167, 1.1883, 1.2257, 1.1088, 1.1765,\n",
       "                      1.2153, 1.3114, 1.2792, 1.2364, 1.2661, 1.2582, 1.2626, 1.2824, 1.2387,\n",
       "                      1.1927, 1.2301, 1.2424, 1.2848, 1.3126, 1.2597, 1.2637, 1.1764, 1.2155,\n",
       "                      1.0910, 0.6032, 1.1395, 1.2855, 1.2233, 0.5262, 1.0868, 1.2298, 1.1604,\n",
       "                      1.2794, 1.2530, 1.2381, 1.2510, 1.2190, 1.1554, 1.2701, 1.1383, 1.2778,\n",
       "                      1.2835, 1.2639, 1.2420, 1.1659, 1.2549, 1.2366, 1.2005, 1.2803, 1.3015,\n",
       "                      1.1748, 1.2365, 1.2501, 1.2488, 1.2496, 1.2320, 1.2272, 1.2433, 1.1995,\n",
       "                      1.3037, 1.2120, 1.2434, 1.2345, 1.2334, 1.2787, 1.2593, 1.2795, 1.2509,\n",
       "                      1.2280, 1.1998, 1.1834, 1.2739, 1.1523, 1.1819, 1.2386, 1.2774, 1.2638,\n",
       "                      1.2850, 1.2606, 1.1682, 1.2736, 1.2897, 1.2406])),\n",
       "             ('transformer.h.5.mlp.c_fc.weight',\n",
       "              tensor([[-0.0754,  0.0161, -0.1050,  ...,  0.0036,  0.0413,  0.0275],\n",
       "                      [-0.0365,  0.0182,  0.0449,  ...,  0.0634, -0.0281,  0.0191],\n",
       "                      [-0.0335, -0.0611,  0.0203,  ..., -0.0111, -0.0757,  0.1699],\n",
       "                      ...,\n",
       "                      [ 0.0869,  0.0977, -0.0601,  ..., -0.0480,  0.0884, -0.0250],\n",
       "                      [ 0.0206,  0.0028,  0.0319,  ..., -0.0548,  0.0230,  0.0064],\n",
       "                      [ 0.0074, -0.0353, -0.0293,  ..., -0.0014,  0.0235, -0.0711]])),\n",
       "             ('transformer.h.5.mlp.c_proj.weight',\n",
       "              tensor([[ 0.0730, -0.0488,  0.0176,  ..., -0.0890, -0.0216,  0.0151],\n",
       "                      [ 0.0393, -0.0156,  0.0660,  ..., -0.0331, -0.0012,  0.0478],\n",
       "                      [-0.0181, -0.0702, -0.0673,  ...,  0.0066, -0.0008,  0.0113],\n",
       "                      ...,\n",
       "                      [-0.0107, -0.0237, -0.0648,  ...,  0.0442, -0.1021, -0.0428],\n",
       "                      [ 0.0091,  0.0077, -0.0068,  ...,  0.0158,  0.0599, -0.0327],\n",
       "                      [-0.0531, -0.0220, -0.0589,  ..., -0.0038,  0.0562, -0.0541]])),\n",
       "             ('transformer.ln_f.weight',\n",
       "              tensor([1.9432, 2.0807, 1.8688, 1.8194, 1.7908, 1.7861, 1.7364, 1.8681, 1.8075,\n",
       "                      1.8713, 1.8750, 1.8032, 2.0156, 1.9572, 1.8312, 2.0438, 2.0527, 1.9548,\n",
       "                      2.0179, 0.9951, 1.9588, 1.9562, 1.9207, 1.8522, 1.8792, 1.4638, 1.9340,\n",
       "                      2.0029, 1.9104, 1.2221, 1.9522, 1.8739, 1.9024, 1.9218, 1.9079, 2.0712,\n",
       "                      1.9779, 1.9238, 1.7943, 1.6416, 1.8229, 1.9799, 1.9061, 1.7570, 1.8909,\n",
       "                      1.8658, 1.8948, 1.8353, 1.8078, 1.8288, 1.9354, 1.8212, 1.9210, 1.8236,\n",
       "                      1.7121, 1.9920, 1.7890, 1.9479, 2.0451, 1.7596, 1.8444, 1.9160, 1.7213,\n",
       "                      1.8116, 1.9714, 1.9114, 2.0203, 1.8933, 1.6812, 1.8484, 1.7764, 1.8100,\n",
       "                      1.9749, 1.9677, 1.8348, 1.8751, 1.0088, 1.9035, 2.0117, 1.9802, 1.9488,\n",
       "                      1.0341, 1.8588, 1.8525, 2.0017, 1.9853, 1.9004, 1.7484, 1.7898, 1.8657,\n",
       "                      1.9813, 1.8033, 1.9773, 1.8366, 1.8707, 1.9067, 1.9818, 1.9845, 1.9144,\n",
       "                      1.9280, 1.9293, 2.0290, 1.7935, 2.0168, 1.9509, 1.8694, 1.8885, 1.8577,\n",
       "                      1.9976, 1.7167, 1.9465, 1.8998, 1.7793, 1.4784, 1.9706, 1.7624, 1.7737,\n",
       "                      1.7731, 1.7856, 1.9882, 1.8851, 1.9144, 1.6438, 1.9877, 1.6511, 2.0179,\n",
       "                      1.9148, 2.0527, 1.8095, 2.1468, 1.9969, 1.9914, 1.8013, 1.9653, 1.8550,\n",
       "                      2.0658, 1.8001, 1.9054, 1.8274, 1.4962, 2.1118, 1.9226, 1.2670, 1.6453,\n",
       "                      1.8551, 1.9305, 1.8171, 1.9024, 2.1348, 1.9803, 1.9413, 1.2767, 1.8490,\n",
       "                      1.8277, 1.7789, 1.7650, 1.8807, 1.7123, 2.0484, 1.8310, 2.0394, 2.0181,\n",
       "                      1.9223, 1.9186, 1.9521, 1.8858, 1.8032, 1.8934, 2.0226, 1.7851, 1.8355,\n",
       "                      1.8949, 1.8807, 1.7408, 1.4419, 1.7837, 1.9618, 1.9520, 1.8993, 1.9104,\n",
       "                      1.8934, 1.8026, 1.7523, 1.9760, 1.9369, 1.9306, 1.6450, 0.6616, 2.0436,\n",
       "                      1.9443, 1.9550, 1.7905, 1.7741, 1.9637, 2.0101, 1.8900, 1.9164, 1.8899,\n",
       "                      1.9766, 1.9272, 1.9727, 0.4322, 1.9839, 1.6082, 1.8582, 1.9337, 1.7993,\n",
       "                      1.9211, 1.8088, 1.9727, 1.2375, 2.2034, 1.8965, 1.8360, 1.8656, 1.8235,\n",
       "                      1.7325, 1.8859, 1.8038, 2.0456, 1.9647, 1.9181, 1.8584, 1.9347, 1.8966,\n",
       "                      2.1707, 1.9219, 1.5048, 1.8320, 1.8601, 1.7921, 1.7819, 1.7976, 1.8369,\n",
       "                      1.9662, 1.7806, 2.0016, 1.9917, 1.9223, 1.6233, 1.6700, 1.9957, 1.9771,\n",
       "                      1.4849, 2.0161, 1.7803, 1.8936, 1.7081, 1.9078, 1.8346, 1.8608, 1.9254,\n",
       "                      2.0398, 1.6971, 1.8459, 2.0483, 1.8961, 1.7532, 2.0083, 1.8752, 2.0455,\n",
       "                      2.0427, 1.7828, 2.1121, 1.7994, 1.6241, 1.7478, 1.9476, 2.0196, 1.7704,\n",
       "                      2.0438, 1.8520, 1.6599, 1.9766, 1.7987, 2.0767, 1.9302, 1.8837, 1.7897,\n",
       "                      1.4709, 1.8825, 1.8922, 1.8595, 1.9693, 2.0885, 1.6092, 1.4605, 1.8174,\n",
       "                      1.7466, 1.7103, 1.9585, 1.9768, 1.8900, 1.9358, 1.8381, 1.9103, 1.8096,\n",
       "                      1.3441, 1.8178, 1.7641, 1.9048, 2.0918, 1.8244, 1.7820, 2.1368, 1.7032,\n",
       "                      1.7220, 1.9386, 1.8685, 1.9666, 2.0092, 1.7736, 1.9047, 1.9818, 1.7676,\n",
       "                      1.9480, 1.8066, 1.8366, 1.9622, 2.0190, 1.9405, 1.8345, 1.7945, 1.9727,\n",
       "                      1.5232, 0.7205, 1.6216, 1.9919, 1.9157, 0.5380, 1.6700, 1.6737, 1.8085,\n",
       "                      1.8962, 1.8195, 1.9852, 1.8886, 2.0619, 2.1037, 1.8634, 1.7131, 1.9811,\n",
       "                      1.9308, 1.9796, 1.8556, 1.6818, 1.9941, 1.9581, 1.8035, 1.9433, 1.9131,\n",
       "                      1.9508, 1.8449, 2.0020, 1.8938, 1.9510, 2.0676, 1.8811, 1.9638, 1.8038,\n",
       "                      1.9882, 1.7592, 2.0313, 2.0082, 1.6505, 2.0683, 1.9279, 1.9286, 1.9571,\n",
       "                      1.9640, 1.9625, 1.5598, 2.0512, 2.0254, 1.7528, 1.9959, 1.8061, 1.9409,\n",
       "                      1.9727, 1.8778, 1.9013, 1.9869, 2.0796, 1.8998])),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[-0.0752,  0.0476,  0.0475,  ...,  0.0478, -0.0786, -0.0520],\n",
       "                      [-0.0718,  0.0046,  0.0576,  ...,  0.0493,  0.1173, -0.0925],\n",
       "                      [-0.0501, -0.0143,  0.0728,  ..., -0.0714,  0.0358, -0.0427],\n",
       "                      ...,\n",
       "                      [-0.1071,  0.0943,  0.0424,  ...,  0.0363, -0.0365, -0.1093],\n",
       "                      [-0.0192,  0.1526, -0.0411,  ..., -0.0109,  0.0851, -0.0512],\n",
       "                      [-0.0548, -0.0823, -0.0603,  ...,  0.0006, -0.0392, -0.0501]]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melek/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "habanoz/haber-90k-gpt-v1.1 does not appear to have a file named config.json. Checkout 'https://huggingface.co/habanoz/haber-90k-gpt-v1.1/tree/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/habanoz/haber-90k-gpt-v1.1/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1282\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1722\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1722\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1654\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:372\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:396\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:315\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    314\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EntryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-669b9bf7-1df67b06609998a912affc21;a9f616cd-c680-4e31-b713-a71cdb144f0d)\n\nEntry Not Found for url: https://huggingface.co/habanoz/haber-90k-gpt-v1.1/resolve/main/config.json.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhabanoz/haber-90k-gpt-v1.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:523\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 523\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:934\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    932\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    936\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/hub.py:453\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m         revision \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    458\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "\u001b[0;31mOSError\u001b[0m: habanoz/haber-90k-gpt-v1.1 does not appear to have a file named config.json. Checkout 'https://huggingface.co/habanoz/haber-90k-gpt-v1.1/tree/main' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"habanoz/haber-90k-gpt-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(8192, 384)\n",
       "    (wpe): Embedding(1024, 384)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=8192, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(8192, 384)\n",
       "    (wpe): Embedding(1024, 384)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=False)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=8192, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = Tokenizer.from_pretrained(trainer_cfg.repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 8108, 8141, 6080, 6610, 4559, 42, 961, 2]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tokenizer.encode(\"# Borsa güne yükselişle başladı\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Turkcell’den bayramda yurt dışı müjdesi ## Özet Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye, 8-8 Mayıs arası gerçekleştirilecek \"Hemen İçin Vuhan Yol Kampı\"nda, başkent Turkcell'de yapılacak, 28-8 Mayıs arası gerçekleşecekleri yeni tip koronavirüs (Kovid-19) salgını sebebiyle çevrim içi arabaların çevrim içi duyurulduğu hesaplandığı açıklandı ## İçerik Turkcell'den yapılan açıklamaya göre, Turkcell’in online eğitim tarihinde ilk kez ailesinin katkısı, Turkcell'in dijitalleştiği bir iş ortağı olma vizyonuyla iş hayatında oluşmaya devam ediyor. Y Mevcut adımların faaliyetlerine en yakın bilgi veren Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye, 8-9 Mayıs arası gerçekleşecek. Turkcell Global Çocuk Koleksiyonu’na 10-8 Mayıs arası gerçekleştirilecekleri yeni tip koronavirüs (Kovid-19) salgını sebebiyle çevrim içi alışverişlerde Garanti BBVA Grubunun avantajları ile yanıtlandı. Turkcell,  ⁇ R kodları ve TWF “Yılın Sosyal Güvenlik Dayanışma Kampı”nda, Turkcell Dijital PSA Türkiye, 7/24 Mayıs tarihlerinde İstanbul Mobil Okrugöz Bisiklet Fonu ve Bisiklet Fonu sosyal pasaportlarına Turkcell tarafından uygulanan \"Hemen İçin Vuhan Yol Kampı\"nda, dijital başka alanlarda ve en çok okuyucuyla buluştı. Turkcell’in sunduğu Dijital PSA Türkiye, 8-8 Mayıs arasındaki anlaşmayı 4 Mayıs’a kadar tamamlayacak. Turkcell Global Çocuk Koleksiyonu ve PSA’nın web sitesi arasında kullanıcılar, gençler, isterseprobassiyonunu mobil platformlarda, performans gösteren bağlı sensörler gibi popülerliğine ulaşmada da önem veren Turkcell Kurumsal Çocuk Koleksiyonu ve PSA’nın dijital denilebilecekleri yeni programda Turkcell'in dijitalleştirici güvenlik projeleri üstlendi. Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye’nin Yurtiçi üyesi olacak LG InP, kullanıcıların bir evle olan kolayca karşılanacağı hediye çekleriyle birlikte sunuluyor. Turkcell tüm Turkcell Cargo, haziran ve içinde gerçekleştirilen tüm Turkcell’in salgın sürecine üye olma vizyonuyla adım adım adım adımı atıyor.\n"
     ]
    }
   ],
   "source": [
    "prompt = torch.tensor(_tokenizer.encode(\"# Turkcell’den bayramda yurt dışı müjdesi\")['input_ids']).view(1, -1)\n",
    "prompt = prompt[:,:-1]\n",
    "for i in range(512):\n",
    "    logits,_ = model(prompt)\n",
    "    logits = logits[:, -1, :]\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    tok = torch.multinomial(probs, 1, replacement=True)\n",
    "    \n",
    "    if tok.item() == 2:\n",
    "        break\n",
    "\n",
    "    prompt = torch.cat((prompt , tok), dim=-1)\n",
    "\n",
    "text = _tokenizer.decode(prompt.tolist()[0])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Turkcell’den bayramda yurt dışı müjdesi ## Özet Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye, 8-8 Mayıs arası gerçekleştirilecek \"Hemen İçin Vuhan Yol Kampı\"nda, başkent Turkcell'de yapılacak, 28-8 Mayıs arası gerçekleşecekleri yeni tip koronavirüs (Kovid-19) salgını sebebiyle çevrim içi arabaların çevrim içi duyurulduğu hesaplandığı açıklandı ## İçerik Turkcell'den yapılan açıklamaya göre, Turkcell’in online eğitim tarihinde ilk kez ailesinin katkısı, Turkcell'in dijitalleştiği bir iş ortağı olma vizyonuyla iş hayatında oluşmaya devam ediyor. Y Mevcut adımların faaliyetlerine en yakın bilgi veren Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye, 8-9 Mayıs arası gerçekleşecek. Turkcell Global Çocuk Koleksiyonu’na 10-8 Mayıs arası gerçekleştirilecekleri yeni tip koronavirüs (Kovid-19) salgını sebebiyle çevrim içi alışverişlerde Garanti BBVA Grubunun avantajları ile yanıtlandı. Turkcell,  ⁇ R kodları ve TWF “Yılın Sosyal Güvenlik Dayanışma Kampı”nda, Turkcell Dijital PSA Türkiye, 7/24 Mayıs tarihlerinde İstanbul Mobil Okrugöz Bisiklet Fonu ve Bisiklet Fonu sosyal pasaportlarına Turkcell tarafından uygulanan \"Hemen İçin Vuhan Yol Kampı\"nda, dijital başka alanlarda ve en çok okuyucuyla buluştı. Turkcell’in sunduğu Dijital PSA Türkiye, 8-8 Mayıs arasındaki anlaşmayı 4 Mayıs’a kadar tamamlayacak. Turkcell Global Çocuk Koleksiyonu ve PSA’nın web sitesi arasında kullanıcılar, gençler, isterseprobassiyonunu mobil platformlarda, performans gösteren bağlı sensörler gibi popülerliğine ulaşmada da önem veren Turkcell Kurumsal Çocuk Koleksiyonu ve PSA’nın dijital denilebilecekleri yeni programda Turkcell'in dijitalleştirici güvenlik projeleri üstlendi. Turkcell Global Çocuk Koleksiyonu ve PSA Türkiye’nin Yurtiçi üyesi olacak LG InP, kullanıcıların bir evle olan kolayca karşılanacağı hediye çekleriyle birlikte sunuluyor. Turkcell tüm Turkcell Cargo, haziran ve içinde gerçekleştirilen tüm Turkcell’in salgın sürecine üye olma vizyonuyla adım adım adım adımı atıyor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"habanoz/haber-90k-gpt-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 81708\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9079\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Turkcell’den bayramda yurt dışı müjdesi\n",
      "\n",
      "## Özet\n",
      "\n",
      "Turkcell, tarifesi ne olursa olsun Turkcell, 5-18 Ağustos'ta yurt dışında olacak bireysel ve kurumsal faturalı tüm müşterilerine 1GB internetin yanı sıra 60 dakika görüşme veya 60 SMS hediye ediyor\n",
      "\n",
      "## İçerik\n",
      "\n",
      "Şirketten yapılan açıklamaya göre, müşterilerini sadece Türkiye’de değil, dünyanın her yerinde en iyi hizmetle buluşturma amacıyla çalışan Turkcell, Kurban Bayramı'nda yurt dışına çıkacak müşterilerine özel bir hediye sunuyor.\n",
      "\n",
      "Bireysel ve kurumsal faturalı tüm Turkcell’liler tarifelerinden bağımsız olarak bayram döneminde yurt dışında yapacakları 1GB’lık internet kullanımının yanı sıra 60 dakika görüşme (arama/aranma) veya 60 SMS’i bayram hediyesi olarak ücretsiz kullanabilecek.\n",
      "\n",
      "88 ülkeyi kapsayan Kurban Bayramı hediyesiyle, Turkcell’liler rahat bir şekilde iletişim kurabilecek. 5-18 Ağustos'ta yurt dışında bulunacaklara otomatik olarak tanımlanacak olan hediyeyle Turkcell müşterileri sevdikleriyle Türkiye’deki gibi bayramlaşacak.\n",
      "\n",
      "-“Turkcell’liler bayramın coşkusunu yurt dışında da yaşayacak”\n",
      "\n",
      "Açıklamada görüşlerine yer verilen Turkcell Genel Müdür Yardımcısı Ömer Barbaros Yiş, şunları kaydetti:\n",
      "\n",
      "“Turkcell olarak sadece yurt içinde değil yurt dışında da müşterilerimizin yanındayız. Ülkemiz ve insanlarımızın için son derece manevi anlamlar taşıyan Kurban Bayramı’nda müşterilerimize yakınlarıyla rahatça bayramlaşabilmeleri için bugüne kadar benzeri olmayan bir hediye sunuyoruz. Bu hediyemiz sayesinde Turkcell’liler gerek internet üzerinden gerekse konuşarak bayramın coşkusunu dünyanın dört bir yanına taşıyacak. Bu vesileyle tüm Türkiye’nin bayramını şimdiden kutlarız.”\n",
      "\n",
      "Yurt dışındaki ilk kullanımda devreye girecek ve 1 saat geçerli olacak hediyenin kullanılabileceği ülkeler şöyle:\n",
      "\n",
      "ABD, Almanya, Arnavutluk, Avustralya, Avusturya, Azerbaycan, Bangladeş, Belçika, Beyaz Rusya, Birleşik Arap Emirlikleri, Bosna Hersek, Brezilya, Bruney, Bulgaristan, Cebelitarık, Çek Cumhuriyeti, Çin, Danimarka, Ekvator, Ermenistan, Estonya, Faroe Adaları, Fiji, Filistin, Finlandiya, Fransa, Guatemala, Güney Afrika, Güney Kore, Gürcistan, Hırvatistan, Hollanda, Hong Kong, Irak, İngiltere, İran, İrlanda, İspanya, İsrail, İsveç, İsviçre, İtalya, İzlanda, Kanada, Karadağ, Katar, Kazakistan, Kıbrıs, Kırgızistan, Kosova, Kosta Rika, Letonya, Lihtenştayn, Litvanya, Lüksemburg, Macaristan, Makao, Makedonya, Malezya, Malta, Mısır, Moldova, Monako, Montserrat, Nepal, Nijer, Norveç, Panama, Polonya, Portekiz, Porto Riko, Romanya, Rusya, San Marino, Sırbistan, Singapur, Slovakya, Slovenya, Sri Lanka, Suudi Arabistan, Tacikistan, Tayland, Tayvan, Tunus, Ukrayna, Uruguay, Yeni Zelanda, Yunanistan.\n"
     ]
    }
   ],
   "source": [
    "print(ds['train']['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Turkcell’den bayramda yurt dışı müjdesi\n",
       "\n",
       "## Özet\n",
       "\n",
       "Turkcell, tarifesi ne olursa olsun Turkcell, 5-18 Ağustos'ta yurt dışında olacak bireysel ve kurumsal faturalı tüm müşterilerine 1GB internetin yanı sıra 60 dakika görüşme veya 60 SMS hediye ediyor\n",
       "\n",
       "## İçerik\n",
       "\n",
       "Şirketten yapılan açıklamaya göre, müşterilerini sadece Türkiye’de değil, dünyanın her yerinde en iyi hizmetle buluşturma amacıyla çalışan Turkcell, Kurban Bayramı'nda yurt dışına çıkacak müşterilerine özel bir hediye sunuyor.\n",
       "\n",
       "Bireysel ve kurumsal faturalı tüm Turkcell’liler tarifelerinden bağımsız olarak bayram döneminde yurt dışında yapacakları 1GB’lık internet kullanımının yanı sıra 60 dakika görüşme (arama/aranma) veya 60 SMS’i bayram hediyesi olarak ücretsiz kullanabilecek.\n",
       "\n",
       "88 ülkeyi kapsayan Kurban Bayramı hediyesiyle, Turkcell’liler rahat bir şekilde iletişim kurabilecek. 5-18 Ağustos'ta yurt dışında bulunacaklara otomatik olarak tanımlanacak olan hediyeyle Turkcell müşterileri sevdikleriyle Türkiye’deki gibi bayramlaşacak.\n",
       "\n",
       "-“Turkcell’liler bayramın coşkusunu yurt dışında da yaşayacak”\n",
       "\n",
       "Açıklamada görüşlerine yer verilen Turkcell Genel Müdür Yardımcısı Ömer Barbaros Yiş, şunları kaydetti:\n",
       "\n",
       "“Turkcell olarak sadece yurt içinde değil yurt dışında da müşterilerimizin yanındayız. Ülkemiz ve insanlarımızın için son derece manevi anlamlar taşıyan Kurban Bayramı’nda müşterilerimize yakınlarıyla rahatça bayramlaşabilmeleri için bugüne kadar benzeri olmayan bir hediye sunuyoruz. Bu hediyemiz sayesinde Turkcell’liler gerek internet üzerinden gerekse konuşarak bayramın coşkusunu dünyanın dört bir yanına taşıyacak. Bu vesileyle tüm Türkiye’nin bayramını şimdiden kutlarız.”\n",
       "\n",
       "Yurt dışındaki ilk kullanımda devreye girecek ve 1 saat geçerli olacak hediyenin kullanılabileceği ülkeler şöyle:\n",
       "\n",
       "ABD, Almanya, Arnavutluk, Avustralya, Avusturya, Azerbaycan, Bangladeş, Belçika, Beyaz Rusya, Birleşik Arap Emirlikleri, Bosna Hersek, Brezilya, Bruney, Bulgaristan, Cebelitarık, Çek Cumhuriyeti, Çin, Danimarka, Ekvator, Ermenistan, Estonya, Faroe Adaları, Fiji, Filistin, Finlandiya, Fransa, Guatemala, Güney Afrika, Güney Kore, Gürcistan, Hırvatistan, Hollanda, Hong Kong, Irak, İngiltere, İran, İrlanda, İspanya, İsrail, İsveç, İsviçre, İtalya, İzlanda, Kanada, Karadağ, Katar, Kazakistan, Kıbrıs, Kırgızistan, Kosova, Kosta Rika, Letonya, Lihtenştayn, Litvanya, Lüksemburg, Macaristan, Makao, Makedonya, Malezya, Malta, Mısır, Moldova, Monako, Montserrat, Nepal, Nijer, Norveç, Panama, Polonya, Portekiz, Porto Riko, Romanya, Rusya, San Marino, Sırbistan, Singapur, Slovakya, Slovenya, Sri Lanka, Suudi Arabistan, Tacikistan, Tayland, Tayvan, Tunus, Ukrayna, Uruguay, Yeni Zelanda, Yunanistan."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(ds['train']['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtr.model.hf_model_config import HfModelConfig\n",
    "from nbtr.model.gpt2 import GPT, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HfModelConfig(gpt_config=GPTConfig.from_yaml(\"../config/news_model.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/habanoz/haber-90k-gpt-v1.1/commit/0215a4ffaf4239231695c96a6e7654a1f5640628', commit_message='Upload model', commit_description='', oid='0215a4ffaf4239231695c96a6e7654a1f5640628', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.push_to_hub(\"habanoz/haber-90k-gpt-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melek/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 13.77M\n"
     ]
    }
   ],
   "source": [
    "from nbtr.decoder import Decoder\n",
    "\n",
    "decoder = Decoder(\"habanoz/haber-90k-gpt-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = decoder.decode(\"# Borsa güne yükselişle başladı\",max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Borsa güne yükselişle başladı ## Özet Borsa İstanbul'dan 30 yıl içinde 9,99 dolardananın yüzde 89'unu oluşturan BIST 10.21, işlem hacmi, yüzde 74 değer kaybederken, geçen yılın aynı ayına göre yüzde 144 azalışla 3,26 yeni (nisan 20.01) alt endeksi yüzde 75,010 ve ikinci el araçlarının direnç,749 seviyesinde dengeleme değer kazanırken, sefer kar ise 7 yeni pazar için 62,166 yeni"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
